{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlIf8OyfKtZy"
      },
      "source": [
        "# 허깅페이스로 나만의 BERT Pretraining 해보기 튜토리얼 자료\n",
        "\n",
        "**진행자:** [윤주성](https://www.linkedin.com/in/joosung-yoon/)<br>\n",
        "**참고자료:** [Pretraining BERT with Hugging Face Transformers](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/pretraining_BERT.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmrAFcYqKs0N"
      },
      "source": [
        "## Introduction\n",
        "### BERT (Bidirectional Encoder Representations from Transformers)\n",
        "컴퓨터비전 분야에서는 ImageNet 데이터로 학습한 모델을 transfer learning(finetuning)하면 모델 성능을 높이는데 뛰어난 효과가 있다고 알려져 있었습니다. 최근 몇 년 동안 자연어처리 분야에서도 이와 비슷한 테크닉을 적용했을때 모델 성능이 크게 개선된다는 것이 밝혀졌습니다. Google에서 발표한 BERT 모델은 단어 사이의 문맥 관계를 attention mechanism을 통해 학습하는 Transformer 기반 모델로 자연어처리 분야에서의 대표적인 Pretraining 모델입니다. 기존 Transformer 구조에서 encoder 부분만을 활용해서 Language model을 학습한 모델입니다. 자세한 내용은 논문을 참조하시기 바랍니다.\n",
        "\n",
        "언어 모델을 학습할때 가장 중요한건 어떤 방법으로 모델을 학습할지 정하는 것입니다. 대부분의 모델은 다음에 나올 단어를 예측합니다 (e.g. `\"버트를 이용한 언어모델 _\"`),\n",
        "이러한 방법은 간단하지만 context를 한 방향으로만 활용할 수 있다는 한계점이 있습니다. BERT는 이러한 한계점을 극복하기 위해 다음의 두가지 방법을 제안했습니다.\n",
        "\n",
        "### Masked Language Modeling (MLM)\n",
        "\n",
        "입력 시퀀스의 15%를 `[MASK]` token으로 변경하고 이 `[MASK]` 토큰 자리에 있던 원래 단어를 예측합니다.\n",
        "\n",
        "### Next Sentence Prediction (NSP)\n",
        "\n",
        "BERT에서는 입력을 pair로 받아서 학습합니다. 입력으로 사용되는 pair의 50%는 같은 문서에서 나머지 50%는 다른 랜덤한 문서에서 가져옵니다. NSP는 pair로 입력된 시퀀스가 같은 문서에서 온 것인지 다른 문서에서 온 것인지를 예측하는 sequence-level task입니다.\n",
        "\n",
        "학습에 사용할 한국어 dataset 허깅페이스 🤗 Datasets을 통해 사용할 수 있습니다.\n",
        "\n",
        "**시작하기 전에 주의할 점**: Colab에서 실습하시게 되면 세션 설정에 반드시 GPU runtime을 설정해주시기 바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SetUp\n",
        "### Installing the requirements"
      ],
      "metadata": {
        "id": "onNZ1fdhW6j8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W3AV5Ax6Kh1d",
        "outputId": "eb6bb4ba-9b9d-4154-f0dc-5a94be77c965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-9tdqpdhw\n",
            "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-9tdqpdhw\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (0.13.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (4.13.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.24.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0.dev0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.24.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.24.0.dev0) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.24.0.dev0) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.24.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.24.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.24.0.dev0) (2022.9.24)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub) (4.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: soynlp in /usr/local/lib/python3.7/dist-packages (0.0.493)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.0.2)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji==1.7.0\n",
            "  Using cached emoji-1.7.0-py3-none-any.whl\n",
            "Installing collected packages: emoji\n",
            "  Attempting uninstall: emoji\n",
            "    Found existing installation: emoji 1.2.0\n",
            "    Uninstalling emoji-1.2.0:\n",
            "      Successfully uninstalled emoji-1.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kss 3.6.4 requires emoji==1.2.0, but you have emoji 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "emoji"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kss in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Collecting emoji==1.2.0\n",
            "  Using cached emoji-1.2.0-py3-none-any.whl (131 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from kss) (2022.6.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from kss) (9.0.0)\n",
            "Installing collected packages: emoji\n",
            "  Attempting uninstall: emoji\n",
            "    Found existing installation: emoji 1.7.0\n",
            "    Uninstalling emoji-1.7.0:\n",
            "      Successfully uninstalled emoji-1.7.0\n",
            "Successfully installed emoji-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "emoji"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install datasets\n",
        "!pip install huggingface-hub\n",
        "!pip install nltk\n",
        "!pip install soynlp \n",
        "!pip install emoji==1.7.0\n",
        "!pip install kss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the necessary libraries"
      ],
      "metadata": {
        "id": "JDoxLifmXF86"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onuT1fSjP2tW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import random\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from kss import split_sentences\n",
        "\n",
        "# nltk.download(\"punkt\")\n",
        "# 에러 메세지만 로깅합니다\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "# 랜덤 시드를 설정합니다\n",
        "tf.keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define certain variables"
      ],
      "metadata": {
        "id": "2faJCyCYXK0N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yFqlXLSQD4W"
      },
      "outputs": [],
      "source": [
        "TOKENIZER_BATCH_SIZE = 256  # 토크나이저를 학습할 때 사용할 배치 사이즈\n",
        "TOKENIZER_VOCABULARY = 25000  # 토크나이저의 vocab 사이즈\n",
        "\n",
        "BLOCK_SIZE = 128  # input sample에 있는 token의 최대 수 \n",
        "NSP_PROB = 0.50  # 다음 문장이 같은 문서에 있을 NSP 확률\n",
        "SHORT_SEQ_PROB = 0.1  # pretraining과 finetuning시 차이를 줄이기 위한 짧은 문장 생성 확률\n",
        "\n",
        "\n",
        "MLM_PROB = 0.15  # 마스킹 MLM 확률 \n",
        "\n",
        "TRAIN_BATCH_SIZE = 2  # 모델 배치 사이즈\n",
        "MAX_EPOCHS = 1  # 모델 최대 에폭\n",
        "LEARNING_RATE = 1e-4  # Learning rate\n",
        "\n",
        "MODEL_CHECKPOINT = \"klue/bert-base\" # 🤗 Model Hub에 올라와 있는 모델명\n",
        "MAX_LENGTH = 512  # input sample을 패딩 처리한 후 토큰의 최대 수"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Wiki dataset\n",
        "Wikipedia 데이터셋은 언어 모델에서 많이 사용되는 데이터셋입니다.  [🤗 허깅페이스의 Datasets](https://github.com/huggingface/datasets) 라이브러리의 load_dataset함수를 통해 데이터를 로딩합니다"
      ],
      "metadata": {
        "id": "d-iHMz2yXPRH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BvxOvDwQVxh",
        "outputId": "cd2c6b96-fac1-4d6f-f14c-b7bf631ddd11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration lcw99--wikipedia-korean-20221001-f565b2ae9e7c9761\n",
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/lcw99___parquet/lcw99--wikipedia-korean-20221001-f565b2ae9e7c9761/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"lcw99/wikipedia-korean-20221001\", split=\"train\") "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UZeGyt_Xnzc",
        "outputId": "74e738bc-10a5-4d79-cdf9-ced505e6b08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'url', 'title', 'text'],\n",
            "    num_rows: 607256\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7IfOIlvQX-p",
        "outputId": "a7ea3858-8ed2-44ea-a3e9-a05223946e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at /root/.cache/huggingface/datasets/lcw99___parquet/lcw99--wikipedia-korean-20221001-f565b2ae9e7c9761/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-86777b6e8e519bd8.arrow and /root/.cache/huggingface/datasets/lcw99___parquet/lcw99--wikipedia-korean-20221001-f565b2ae9e7c9761/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-3b140210994e4787.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'url', 'title', 'text'],\n",
            "        num_rows: 546530\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'url', 'title', 'text'],\n",
            "        num_rows: 60726\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "TRAIN_TEST_SPLIT = 0.1\n",
        "\n",
        "dataset = dataset.train_test_split(\n",
        "    train_size=1-TRAIN_TEST_SPLIT, test_size=TRAIN_TEST_SPLIT\n",
        ")\n",
        "dataset['validation'] = dataset['test']\n",
        "del dataset['test']\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o68fZfQ3vRHn",
        "outputId": "3ff20f6a-de1f-4b27-a920-b3aee37ebbb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '1773240',\n",
              " 'url': 'https://ko.wikipedia.org/wiki/%EC%A7%84%EC%B4%8C%EB%A6%AC',\n",
              " 'title': '진촌리',\n",
              " 'text': '진촌리는 다음 지역에 위치한 대한민국의 리이다.\\n\\n 인천광역시 옹진군 백령면 진촌리(鎭村里)\\n 경기도 안성시 미양면 진촌리(眞村里)\\n 경기도 안성시 삼죽면 진촌리(眞村里)\\n\\n같이 보기 \\n\\n대한민국의 리'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a new Tokenizer\n",
        "나만의 언어 모델을 만들기전에 주어진 corpus로부터 나만의 tokenizer를 학습 할수 있습니다.  \n",
        "Transformer 모델들은 대부분 subword tokenization algorithms을 사용하기 때문에 우리가 사용하는 corpus에 맞는 tokenizer를 학습하는 것이 필요할 수 있습니다.  \n",
        "🤗 Transformers 라이브러리에 있는 `Tokenizer`를 통해 학습을 진행합니다.  \n",
        "먼저 Wiki corpus dataset으로부터 raw document를 가져옵니다."
      ],
      "metadata": {
        "id": "Do2Vj_tqX6KW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4MF3k2VQbDU"
      },
      "outputs": [],
      "source": [
        "all_texts = [\n",
        "    doc for doc in dataset[\"train\"][\"text\"] if len(doc) > 0\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`batch_iterator` 를 통해 tokenizer 학습에 필요한 데이터를 전달해줍니다.  \n",
        "`VOCAB_TRAIN_DOC_SIZE`는 tokenizer를 학습할 corpus 규모에 따라 설정할 수 있습니다.  \n",
        "실습 진행을 위해 5000개의 문서만 사용하겠습니다."
      ],
      "metadata": {
        "id": "3-VW0_ilZCVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze2q6AdzQeHG"
      },
      "outputs": [],
      "source": [
        "# tokenizer 학습셋 구축\n",
        "VOCAB_TRAIN_DOC_SIZE = 5000\n",
        "\n",
        "def batch_iterator():\n",
        "    for i in tqdm(range(0, VOCAB_TRAIN_DOC_SIZE, TOKENIZER_BATCH_SIZE)):\n",
        "        yield all_texts[i : i + TOKENIZER_BATCH_SIZE]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 예제에서는 기존에 공개된 알고리즘과 파라미터를 공유하는 `klue/bert-base` 모델의 토크나이저를 가져와서 재학습하고자 합니다.  \n",
        "이를 위해 먼저 tokenizer를 로딩합니다."
      ],
      "metadata": {
        "id": "IJv236PlZWpj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-geGDlEQfpB",
        "outputId": "03a07c31-5239-400b-bbc5-26ed1dd19811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer from: klue/bert-base\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "print(f\"tokenizer from: {MODEL_CHECKPOINT}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 tokenizer를 Wiki 데이터셋에 대해서 재학습합니다."
      ],
      "metadata": {
        "id": "hx0yOomcZyI4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd7C3rL4QhY4",
        "outputId": "5243ff56-befc-434b-d029-d7068c915be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 23.57it/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tokenizer.train_new_from_iterator(\n",
        "    batch_iterator(), vocab_size=TOKENIZER_VOCABULARY\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "재학습이 끝난 후 나만의 새로운 토크나이저를 얻게 되었습니다. 다음 전처리 스텝으로 이동해보겠습니다."
      ],
      "metadata": {
        "id": "2K6dLuFVZ6pP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gUZZzwhFx35",
        "outputId": "67d1281e-7b36-4c87-b0e8-dafd692ed87d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='klue/bert-base', vocab_size=25000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-processing\n",
        "전체적인 학습과정을 실습하기 위해 데이터셋의 일부만 샘플링해서 학습에 적용하겠습니다.  \n",
        "beomi님의 kcbert에서 사용하는 한글 전처리 로직을 통해 corpus를 전체적으로 전처리하겠습니다."
      ],
      "metadata": {
        "id": "wSik0FPFaD_b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "medJU7CeQlXF"
      },
      "outputs": [],
      "source": [
        "DOC_NUM = 500\n",
        "dataset[\"train\"] = dataset[\"train\"].select([i for i in range(DOC_NUM)])\n",
        "dataset[\"validation\"] = dataset[\"validation\"].select([i for i in range(DOC_NUM)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQpShP9HQZ5s"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import emoji\n",
        "from soynlp.normalizer import repeat_normalize\n",
        "\n",
        "emojis = list({y for x in emoji.UNICODE_EMOJI.values() for y in x.keys()})\n",
        "emojis = ''.join(emojis)\n",
        "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣{emojis}]+')\n",
        "url_pattern = re.compile(\n",
        "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
        "\n",
        "# 학습데이터셋 전처리 함수\n",
        "def clean(ds):\n",
        "    \"\"\"\n",
        "    ref: https://huggingface.co/beomi/kcbert-base\n",
        "    \"\"\"\n",
        "    x = ds['text']\n",
        "    x = pattern.sub(' ', x)\n",
        "    x = url_pattern.sub('', x)\n",
        "    x = x.strip()\n",
        "    x = repeat_normalize(x, num_repeats=2)\n",
        "    ds['text'] = x\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS7CvC0tCgiR",
        "outputId": "94431688-5bcf-4287-abf2-6f19ebec8d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/lcw99___parquet/lcw99--wikipedia-korean-20221001-f565b2ae9e7c9761/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-db8241db64695f29.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/lcw99___parquet/lcw99--wikipedia-korean-20221001-f565b2ae9e7c9761/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-504d8f9ecd4968b3.arrow\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.map(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA0VlJ4dy_Vz",
        "outputId": "89ac0dd8-5c65-4ef8-9eed-7b820842e022"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '1773240',\n",
              " 'url': 'https://ko.wikipedia.org/wiki/%EC%A7%84%EC%B4%8C%EB%A6%AC',\n",
              " 'title': '진촌리',\n",
              " 'text': '진촌리는 다음 지역에 위치한 대한민국의 리이다. 인천광역시 옹진군 백령면 진촌리( ) 경기도 안성시 미양면 진촌리( ) 경기도 안성시 삼죽면 진촌리( ) 같이 보기 대한민국의 리'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT는 학습은 크게 MLM, NSP task로 구성되어있습니다.  \n",
        "MLM task는 Transformers에서 `DataCollatorForLanguageModeling`를 통해 쉽게 구현할 수 있지만 `NSP`의 경우 직접 작업이 필요합니다.   \n",
        "`prepare_train_features` 함수를 통해 `NSP`task를 위한 sentence pair (A, B) 를 구성해보겠습니다.\n",
        "\n",
        "문장 분리를 위해 영어는 `nltk.tokenize.sent_tokenize`, 한국어는  `kss.split_sentences` 함수를 사용하겠습니다."
      ],
      "metadata": {
        "id": "8zqll9o2bMsx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "dfe0c1bd2f9f4f129bd1171a028d0152",
            "81b7897333794e0b80a7d267a55abcc5",
            "d9c40a35d55649adb0fb650006a58e2c",
            "f11ebd57783140a7b34c158a29847f2e",
            "4b92ca23450942c98b0c6f8c09645236",
            "f34d653b8ab544f9a7b887b5af52b4b2",
            "41b065ae078049029949329c5f9b463f",
            "531526bd22ed448686dfc0e1108e0944",
            "569224f865014978bff0ef6dd114ab38",
            "c29595d1c9884bc5b3783e0e6d52cb2a",
            "66ec9304891246ffbfec96a948447303",
            "7aa71facb49e4033865b1175088c5002",
            "00ab10d1ea45472982c8610e5bf44a3a",
            "02e60c05151c477d820ba7f2f7d220e7",
            "2422f0e9f87d41e9bbbabd25356ea1da",
            "cb92fd0be68d40bc9d10ab5e6b233498",
            "a47c4c31b4c446759aabb6615608caaf",
            "34b50123ce114cc1a8ac39bf8992e5b7",
            "e19c34c43ebd49d0977664cd4afc1b79",
            "637ae55c74314aea91160c00cd3aa0bc",
            "d4a2d2bc4ce648298319171c1055943d",
            "d6c5907da43048aa8ed641268e3cfe75"
          ]
        },
        "id": "aBcKCKMnQm6Z",
        "outputId": "c94b113c-b8b6-46c4-f460-951288219b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_num_tokens:125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfe0c1bd2f9f4f129bd1171a028d0152"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Too long text! turn off quotes calibration!\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aa71facb49e4033865b1175088c5002"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Too long text! turn off quotes calibration!\n"
          ]
        }
      ],
      "source": [
        "# 학습 샘플에 대한 max_num_tokens 정의\n",
        "max_num_tokens = BLOCK_SIZE - tokenizer.num_special_tokens_to_add(pair=True)\n",
        "print(f\"max_num_tokens:{max_num_tokens}\")\n",
        "\n",
        "def prepare_train_features(examples):\n",
        "\n",
        "    \"\"\"NSP task를 위한 Function \n",
        "\n",
        "    Arguments:\n",
        "      examples: A dictionary with 1 key (\"text\")\n",
        "        text: List of raw documents (str)\n",
        "    Returns:\n",
        "      examples:  A dictionary with 4 keys\n",
        "        input_ids: List of tokenized, concatnated, and batched\n",
        "          sentences from the individual raw documents (int)\n",
        "        token_type_ids: List of integers (0 or 1) corresponding\n",
        "          to: 0 for senetence no. 1 and padding, 1 for sentence\n",
        "          no. 2\n",
        "        attention_mask: List of integers (0 or 1) corresponding\n",
        "          to: 1 for non-padded tokens, 0 for padded\n",
        "        next_sentence_label: List of integers (0 or 1) corresponding\n",
        "          to: 1 if the second sentence actually follows the first,\n",
        "          0 if the senetence is sampled from somewhere else in the corpus\n",
        "    \"\"\"\n",
        "\n",
        "    # 학습에 사용할 유효 데이터셋 필터링\n",
        "    examples[\"document\"] = [\n",
        "        d.strip() for d in examples[\"text\"] if len(d) > 0\n",
        "    ]\n",
        "    # 문서를 문장 단위로 쪼개기\n",
        "    examples[\"sentences\"] = [\n",
        "        # nltk.tokenize.sent_tokenize(document) for document in examples[\"document\"]\n",
        "        split_sentences(document) for document in examples[\"document\"]        \n",
        "    ]\n",
        "    # 학습한 tokenizer로 token -> token_id로 변환\n",
        "    examples[\"tokenized_sentences\"] = [\n",
        "        [tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent)) for sent in doc]\n",
        "        for doc in examples[\"sentences\"]\n",
        "    ]\n",
        "\n",
        "    # 출력 변수 정의\n",
        "    examples[\"input_ids\"] = []\n",
        "    examples[\"token_type_ids\"] = []\n",
        "    examples[\"attention_mask\"] = []\n",
        "    examples[\"next_sentence_label\"] = []\n",
        "\n",
        "    for doc_index, document in enumerate(examples[\"tokenized_sentences\"]):\n",
        "        \n",
        "        current_chunk = []  # 현재 처리하고 있는 segment를 저장하는 chunk\n",
        "        current_length = 0\n",
        "        i = 0\n",
        "\n",
        "        # 보통의 경우 short sequence는 학습에 비효율적이지만, pretraining과 finetuning의 갭을 줄이기 위해 \n",
        "        # 의도적으로 SHORT_SEQ_PROB(10%)만큼 short seq를 추가해줍니다\n",
        "        target_seq_length = max_num_tokens\n",
        "\n",
        "        if random.random() < SHORT_SEQ_PROB:\n",
        "            target_seq_length = random.randint(2, max_num_tokens) # 2~max_num_tokens 사이의 random length 생성\n",
        "\n",
        "        while i < len(document):\n",
        "            segment = document[i]\n",
        "            current_chunk.append(segment)\n",
        "            current_length += len(segment)\n",
        "\n",
        "            # 처음에 로직에 진입할 조건 or max token수보다 길이가 긴 경우 진입\n",
        "            if i == len(document) - 1 or current_length >= target_seq_length:\n",
        "                if current_chunk:\n",
        "                    # `a_end` 변수는 `current_chunk`에 있는 세그먼트중 몇개가 first sentence에 들어갈지를 나타냄\n",
        "                    a_end = 1\n",
        "\n",
        "                    # chunk가 2개 이상이면 랜덤하게 1개 이상의 chunk 개수를 선택 후 \n",
        "                    # first sentence에 추가해줘서 target_seq_length를 넘지 않는 first sentence를 만듦\n",
        "                    if len(current_chunk) >= 2:\n",
        "                        a_end = random.randint(1, len(current_chunk) - 1)\n",
        "\n",
        "                    # tokens_a에 current_chunk를 저장\n",
        "                    tokens_a = []\n",
        "                    for j in range(a_end):\n",
        "                        tokens_a.extend(current_chunk[j])\n",
        "\n",
        "                    tokens_b = []\n",
        "\n",
        "                    if len(current_chunk) == 1 or random.random() < NSP_PROB:\n",
        "                        # 랜덤 문서 선택하는 케이스\n",
        "                        is_random_next = True\n",
        "                        target_b_length = target_seq_length - len(tokens_a)\n",
        "\n",
        "                        # 랜덤하게 선택한 문서가 기존과 같은 문서인지 체크\n",
        "                        for _ in range(10):\n",
        "                            random_document_index = random.randint(\n",
        "                                0, len(examples[\"tokenized_sentences\"]) - 1\n",
        "                            )\n",
        "                            if random_document_index != doc_index:\n",
        "                                break\n",
        "\n",
        "                        # 랜덤 문서 추출\n",
        "                        random_document = examples[\"tokenized_sentences\"][\n",
        "                            random_document_index\n",
        "                        ]\n",
        "\n",
        "                        # 랜덤 문서 내에서 임의의 시작점 추출\n",
        "                        random_start = random.randint(0, len(random_document) - 1)\n",
        "\n",
        "                        # 랜덤 문서에서 임의의 토큰들 추출, target_b_length에 도달하면 스탑\n",
        "                        for j in range(random_start, len(random_document)):\n",
        "                            tokens_b.extend(random_document[j])\n",
        "                            if len(tokens_b) >= target_b_length:\n",
        "                                break\n",
        "                        \n",
        "                        # 사용하지 않은 segment만큼 다시 i 를 복원해줌\n",
        "                        num_unused_segments = len(current_chunk) - a_end\n",
        "                        i -= num_unused_segments\n",
        "                    else:\n",
        "                        # 같은 문서 선택하는 케이스\n",
        "                        is_random_next = False\n",
        "\n",
        "                        # 현재 문서에서 먼저 추출된 토큰 뒷부분 부터 추출\n",
        "                        for j in range(a_end, len(current_chunk)):\n",
        "                            tokens_b.extend(current_chunk[j])\n",
        "\n",
        "                    input_ids = tokenizer.build_inputs_with_special_tokens(\n",
        "                        tokens_a, tokens_b\n",
        "                    )\n",
        "                    # token type ids를 추가함. sentence A에는 0을, sentence B에는 1을 값으로 줌\n",
        "                    token_type_ids = tokenizer.create_token_type_ids_from_sequences(\n",
        "                        tokens_a, tokens_b\n",
        "                    )\n",
        "\n",
        "                    padded = tokenizer.pad(\n",
        "                        {\"input_ids\": input_ids, \"token_type_ids\": token_type_ids},\n",
        "                        padding=\"max_length\",\n",
        "                        max_length=MAX_LENGTH\n",
        "                    )                    \n",
        "                    \n",
        "                    # MAX_LENGTH 이하의 문서만 남도록 길이 수정\n",
        "                    for k, v in padded.items():\n",
        "                      padded[k] = v[:MAX_LENGTH]\n",
        "\n",
        "\n",
        "                    examples[\"input_ids\"].append(padded[\"input_ids\"])\n",
        "                    examples[\"token_type_ids\"].append(padded[\"token_type_ids\"])\n",
        "                    examples[\"attention_mask\"].append(padded[\"attention_mask\"])\n",
        "                    examples[\"next_sentence_label\"].append(1 if is_random_next else 0)\n",
        "                    \n",
        "                    current_chunk = []\n",
        "                    current_length = 0\n",
        "            i += 1\n",
        "\n",
        "    # 데이터셋에서 사용하지 않는 column 제거\n",
        "    del examples[\"document\"]\n",
        "    del examples[\"sentences\"]\n",
        "    del examples[\"text\"]\n",
        "    del examples[\"tokenized_sentences\"]\n",
        "\n",
        "    return examples\n",
        "\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    prepare_train_features, batched=True, remove_columns=['id', 'url', 'title', 'text'], num_proc=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLM task는 입력 토큰의 일부를 `[MASK]`로 교체하는데, `DataCollatorForLanguageModeling`를 통해 쉽게 구현 할 수 있습니다."
      ],
      "metadata": {
        "id": "8WhuuMMmcNLT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dimYrpfQvfV"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "collater = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=MLM_PROB, return_tensors=\"tf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMC1-Hk9QwsE"
      },
      "outputs": [],
      "source": [
        "train = tokenized_dataset[\"train\"].to_tf_dataset(\n",
        "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
        "    label_cols=[\"labels\", \"next_sentence_label\"],\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collater,\n",
        ")\n",
        "\n",
        "validation = tokenized_dataset[\"validation\"].to_tf_dataset(\n",
        "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
        "    label_cols=[\"labels\", \"next_sentence_label\"],\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collater,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the model\n",
        "모델을 정의하기 위해 어떤 모델에 대한 config를 쓸 것인지에 대한 정보가 필요합니다.  \n",
        "본 실습에서는 `klue/bert-base` 모델에 대한 config 정보를 사용합니다."
      ],
      "metadata": {
        "id": "5iFZEAYecpK9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfa09Sw2Q4f9"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig.from_pretrained(MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습을 위해 🤗Transformers 라이브러리의 `TFBertForPreTraining` 클래스를 사용합니다."
      ],
      "metadata": {
        "id": "QBmNHMPYdLAt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kxHs7mRdd2P"
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertForPreTraining\n",
        "\n",
        "model = TFBertForPreTraining(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimizer를 정의하고 모델을 compile해줍니다.  \n",
        "이때 loss에 대한 계산은 내부적으로 이뤄집니다. "
      ],
      "metadata": {
        "id": "K2oG_gepdX2K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbUqlKk2Q64c",
        "outputId": "d492768d-f4db-49cc-be6d-3c514a251d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        }
      ],
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "셋팅이 완료되었으므로 모델 학습을 시작해보겠습니다."
      ],
      "metadata": {
        "id": "02g70x-Hdk70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmOD2Qj9Q-dk",
        "outputId": "07fa3331-6a48-4a8d-eccf-47bb848b5617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000/1000 [==============================] - 443s 427ms/step - loss: 9.5061 - val_loss: 9.4193\n",
            "CPU times: user 4min 52s, sys: 1min, total: 5min 52s\n",
            "Wall time: 7min 22s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62ec0215d0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "%%time\n",
        "model.fit(train, validation_data=validation, epochs=MAX_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습한 모델은 다음과 같이 로컬에 저장할 수 있습니다."
      ],
      "metadata": {
        "id": "qLVz2qsWdszU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-vbuXSbSE46"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"keras-bert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xazMV6rZJoLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9955b3-0e71-4214-a72f-cec43ca2dc7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json  tf_model.h5\n"
          ]
        }
      ],
      "source": [
        "!ls keras-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiosNZNaG9rf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a18b79-7801-4e38-8d33-9949788d93aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.448245108127594,\n",
              "  'token': 3671,\n",
              "  'token_str': '서울',\n",
              "  'sequence': '대한민국의 수도는 서울 입니다'},\n",
              " {'score': 0.08845192939043045,\n",
              "  'token': 9474,\n",
              "  'token_str': '광화문',\n",
              "  'sequence': '대한민국의 수도는 광화문 입니다'},\n",
              " {'score': 0.06651604175567627,\n",
              "  'token': 3902,\n",
              "  'token_str': '부산',\n",
              "  'sequence': '대한민국의 수도는 부산 입니다'},\n",
              " {'score': 0.04384538158774376,\n",
              "  'token': 7141,\n",
              "  'token_str': '평양',\n",
              "  'sequence': '대한민국의 수도는 평양 입니다'},\n",
              " {'score': 0.03615731745958328,\n",
              "  'token': 4431,\n",
              "  'token_str': '대전',\n",
              "  'sequence': '대한민국의 수도는 대전 입니다'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# fill_mask = pipeline(\"fill-mask\", \n",
        "#                      model='./keras-bert', \n",
        "#                      tokenizer=tokenizer, \n",
        "#                      framework=\"tf\")\n",
        "\n",
        "fill_mask = pipeline(\"fill-mask\", \n",
        "                     model=\"klue/bert-base\")\n",
        "\n",
        "fill_mask(\"대한민국의 수도는 [MASK]입니다\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boiuMKdZRTjB"
      },
      "source": [
        "학습한 모델은 다음과 같은 model명(e.g. `\"your-username/the-name-you-picked\"`)을 설정 후 Hugging Face Model Hub에 올릴 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "model.push_to_hub(\"pretrained-bert\", organization=\"keras-io\")\n",
        "tokenizer.push_to_hub(\"pretrained-bert\", organization=\"keras-io\")\n",
        "```\n",
        "\n",
        "모델이 model hub에 푸시되면 아래와 같은 방법으로 로딩할 수 있습니다.\n",
        "\n",
        "```python\n",
        "from transformers import TFBertForPreTraining\n",
        "\n",
        "model = TFBertForPreTraining.from_pretrained(\"your-username/my-awesome-model\")\n",
        "```\n",
        "finetuning 할 때는 아래와 같이 로딩이 가능합니다.\n",
        "\n",
        "```python\n",
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"your-username/my-awesome-model\")\n",
        "```\n",
        "이 경우에는, pretraining head가 로딩되지 않고 새로운 task에 맞는 head가 랜덤하게 초기화되서 추가됩니다.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dfe0c1bd2f9f4f129bd1171a028d0152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81b7897333794e0b80a7d267a55abcc5",
              "IPY_MODEL_d9c40a35d55649adb0fb650006a58e2c",
              "IPY_MODEL_f11ebd57783140a7b34c158a29847f2e"
            ],
            "layout": "IPY_MODEL_4b92ca23450942c98b0c6f8c09645236"
          }
        },
        "81b7897333794e0b80a7d267a55abcc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34d653b8ab544f9a7b887b5af52b4b2",
            "placeholder": "​",
            "style": "IPY_MODEL_41b065ae078049029949329c5f9b463f",
            "value": "  0%"
          }
        },
        "d9c40a35d55649adb0fb650006a58e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_531526bd22ed448686dfc0e1108e0944",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_569224f865014978bff0ef6dd114ab38",
            "value": 0
          }
        },
        "f11ebd57783140a7b34c158a29847f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c29595d1c9884bc5b3783e0e6d52cb2a",
            "placeholder": "​",
            "style": "IPY_MODEL_66ec9304891246ffbfec96a948447303",
            "value": " 0/1 [00:47&lt;?, ?ba/s]"
          }
        },
        "4b92ca23450942c98b0c6f8c09645236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34d653b8ab544f9a7b887b5af52b4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b065ae078049029949329c5f9b463f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "531526bd22ed448686dfc0e1108e0944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "569224f865014978bff0ef6dd114ab38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c29595d1c9884bc5b3783e0e6d52cb2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66ec9304891246ffbfec96a948447303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aa71facb49e4033865b1175088c5002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00ab10d1ea45472982c8610e5bf44a3a",
              "IPY_MODEL_02e60c05151c477d820ba7f2f7d220e7",
              "IPY_MODEL_2422f0e9f87d41e9bbbabd25356ea1da"
            ],
            "layout": "IPY_MODEL_cb92fd0be68d40bc9d10ab5e6b233498"
          }
        },
        "00ab10d1ea45472982c8610e5bf44a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a47c4c31b4c446759aabb6615608caaf",
            "placeholder": "​",
            "style": "IPY_MODEL_34b50123ce114cc1a8ac39bf8992e5b7",
            "value": "  0%"
          }
        },
        "02e60c05151c477d820ba7f2f7d220e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e19c34c43ebd49d0977664cd4afc1b79",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_637ae55c74314aea91160c00cd3aa0bc",
            "value": 0
          }
        },
        "2422f0e9f87d41e9bbbabd25356ea1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a2d2bc4ce648298319171c1055943d",
            "placeholder": "​",
            "style": "IPY_MODEL_d6c5907da43048aa8ed641268e3cfe75",
            "value": " 0/1 [00:50&lt;?, ?ba/s]"
          }
        },
        "cb92fd0be68d40bc9d10ab5e6b233498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a47c4c31b4c446759aabb6615608caaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34b50123ce114cc1a8ac39bf8992e5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e19c34c43ebd49d0977664cd4afc1b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637ae55c74314aea91160c00cd3aa0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4a2d2bc4ce648298319171c1055943d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c5907da43048aa8ed641268e3cfe75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
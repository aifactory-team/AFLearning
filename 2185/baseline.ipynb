{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84817f3",
   "metadata": {},
   "source": [
    "# Classification with Tensorflow Decision Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e82a1",
   "metadata": {},
   "source": [
    "# Contents\n",
    "## 1. Ensemble Tree 모델 리뷰\n",
    "## 2. Census-Income 데이터를 이용하여 income-level 예측\n",
    "## 3. Experiments (Keras)\n",
    "###   3.1 Decision Forests with raw features\n",
    "###   3.2 Decision Forests with target encoding\n",
    "###   3.3 Decision Forests with trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f377a2e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3462ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 12:40:41.426295: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-24 12:40:42.182730: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-24 12:40:44.810716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dhlee/anaconda3/envs/p38/lib:{LD_LIBRARY_PATH}\n",
      "2022-10-24 12:40:44.811120: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dhlee/anaconda3/envs/p38/lib:{LD_LIBRARY_PATH}\n",
      "2022-10-24 12:40:44.811136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "# GPU version 에서 오류가 있어서 cpu 에서 실행함.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "tfdf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a77d887",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2136bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 ['age', 'class_of_worker', 'detailed_industry_recode', 'detailed_occupation_recode', 'education', 'wage_per_hour', 'enroll_in_edu_inst_last_wk', 'marital_stat', 'major_industry_code', 'major_occupation_code', 'race', 'hispanic_origin', 'sex', 'member_of_a_labor_union', 'reason_for_unemployment', 'full_or_part_time_employment_stat', 'capital_gains', 'capital_losses', 'dividends_from_stocks', 'tax_filer_stat', 'region_of_previous_residence', 'state_of_previous_residence', 'detailed_household_and_family_stat', 'detailed_household_summary_in_household', 'instance_weight', 'migration_code-change_in_msa', 'migration_code-change_in_reg', 'migration_code-move_within_reg', 'live_in_this_house_1_year_ago', 'migration_prev_res_in_sunbelt', 'num_persons_worked_for_employer', 'family_members_under_18', 'country_of_birth_father', 'country_of_birth_mother', 'country_of_birth_self', 'citizenship', 'own_business_or_self_employed', \"fill_inc_questionnaire_for_veteran's_admin\", 'veterans_benefits', 'weeks_worked_in_year', 'year']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "BASE_PATH 에서 header와 data(train.gz, test.gz) 를 다운로드함.\n",
    "header 에 income_level 이라는 target_label 추가\n",
    "'''\n",
    "\n",
    "BASE_PATH = 'https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income'\n",
    "url_name = f'{BASE_PATH}.names'\n",
    "url_train_data = f'{BASE_PATH}.data.gz'\n",
    "url_test_data = f'{BASE_PATH}.test.gz'\n",
    "\n",
    "CSV_HEADER = [l.decode('utf-8').split(':')[0].replace(' ', '_') for l in urllib.request.urlopen(url_name) if not l.startswith(b'|')][2:]\n",
    "print(len(CSV_HEADER), CSV_HEADER)\n",
    "\n",
    "# target column 에 대한 헤더 추가\n",
    "CSV_HEADER.append('income_level')\n",
    "\n",
    "test_data = pd.read_csv(url_test_data, header=None, names=CSV_HEADER)\n",
    "train_data = pd.read_csv(url_train_data, header=None, names=CSV_HEADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9136d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>detailed_industry_recode</th>\n",
       "      <th>detailed_occupation_recode</th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>capital_gains</th>\n",
       "      <th>capital_losses</th>\n",
       "      <th>dividends_from_stocks</th>\n",
       "      <th>instance_weight</th>\n",
       "      <th>num_persons_worked_for_employer</th>\n",
       "      <th>own_business_or_self_employed</th>\n",
       "      <th>veterans_benefits</th>\n",
       "      <th>weeks_worked_in_year</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.00000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "      <td>199523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.494199</td>\n",
       "      <td>15.352320</td>\n",
       "      <td>11.306556</td>\n",
       "      <td>55.426908</td>\n",
       "      <td>434.71899</td>\n",
       "      <td>37.313788</td>\n",
       "      <td>197.529533</td>\n",
       "      <td>1740.380269</td>\n",
       "      <td>1.956180</td>\n",
       "      <td>0.175438</td>\n",
       "      <td>1.514833</td>\n",
       "      <td>23.174897</td>\n",
       "      <td>94.499672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.310895</td>\n",
       "      <td>18.067129</td>\n",
       "      <td>14.454204</td>\n",
       "      <td>274.896454</td>\n",
       "      <td>4697.53128</td>\n",
       "      <td>271.896428</td>\n",
       "      <td>1984.163658</td>\n",
       "      <td>993.768156</td>\n",
       "      <td>2.365126</td>\n",
       "      <td>0.553694</td>\n",
       "      <td>0.851473</td>\n",
       "      <td>24.411488</td>\n",
       "      <td>0.500001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.870000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1061.615000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1618.310000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2188.610000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>99999.00000</td>\n",
       "      <td>4608.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>18656.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  detailed_industry_recode  detailed_occupation_recode  \\\n",
       "count  199523.000000             199523.000000               199523.000000   \n",
       "mean       34.494199                 15.352320                   11.306556   \n",
       "std        22.310895                 18.067129                   14.454204   \n",
       "min         0.000000                  0.000000                    0.000000   \n",
       "25%        15.000000                  0.000000                    0.000000   \n",
       "50%        33.000000                  0.000000                    0.000000   \n",
       "75%        50.000000                 33.000000                   26.000000   \n",
       "max        90.000000                 51.000000                   46.000000   \n",
       "\n",
       "       wage_per_hour  capital_gains  capital_losses  dividends_from_stocks  \\\n",
       "count  199523.000000   199523.00000   199523.000000          199523.000000   \n",
       "mean       55.426908      434.71899       37.313788             197.529533   \n",
       "std       274.896454     4697.53128      271.896428            1984.163658   \n",
       "min         0.000000        0.00000        0.000000               0.000000   \n",
       "25%         0.000000        0.00000        0.000000               0.000000   \n",
       "50%         0.000000        0.00000        0.000000               0.000000   \n",
       "75%         0.000000        0.00000        0.000000               0.000000   \n",
       "max      9999.000000    99999.00000     4608.000000           99999.000000   \n",
       "\n",
       "       instance_weight  num_persons_worked_for_employer  \\\n",
       "count    199523.000000                    199523.000000   \n",
       "mean       1740.380269                         1.956180   \n",
       "std         993.768156                         2.365126   \n",
       "min          37.870000                         0.000000   \n",
       "25%        1061.615000                         0.000000   \n",
       "50%        1618.310000                         1.000000   \n",
       "75%        2188.610000                         4.000000   \n",
       "max       18656.300000                         6.000000   \n",
       "\n",
       "       own_business_or_self_employed  veterans_benefits  weeks_worked_in_year  \\\n",
       "count                  199523.000000      199523.000000         199523.000000   \n",
       "mean                        0.175438           1.514833             23.174897   \n",
       "std                         0.553694           0.851473             24.411488   \n",
       "min                         0.000000           0.000000              0.000000   \n",
       "25%                         0.000000           2.000000              0.000000   \n",
       "50%                         0.000000           2.000000              8.000000   \n",
       "75%                         0.000000           2.000000             52.000000   \n",
       "max                         2.000000           2.000000             52.000000   \n",
       "\n",
       "                year  \n",
       "count  199523.000000  \n",
       "mean       94.499672  \n",
       "std         0.500001  \n",
       "min        94.000000  \n",
       "25%        94.000000  \n",
       "50%        94.000000  \n",
       "75%        95.000000  \n",
       "max        95.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01436324",
   "metadata": {},
   "source": [
    "### Define dataset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29b4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Target 및 weight 열 지정\n",
    "Numeric 과 Categorical feature 구분\n",
    "'''\n",
    "\n",
    "# Target column name.\n",
    "TARGET_COLUMN_NAME = \"income_level\"\n",
    "# The labels of the target columns.\n",
    "TARGET_LABELS = [\" - 50000.\", \" 50000+.\"]\n",
    "# Weight column name.\n",
    "WEIGHT_COLUMN_NAME = \"instance_weight\"\n",
    "# Numeric feature names.\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"age\",\n",
    "    \"wage_per_hour\",\n",
    "    \"capital_gains\",\n",
    "    \"capital_losses\",\n",
    "    \"dividends_from_stocks\",\n",
    "    \"num_persons_worked_for_employer\",\n",
    "    \"weeks_worked_in_year\",\n",
    "]\n",
    "# Categorical features and their vocabulary lists.\n",
    "CATEGORICAL_FEATURE_NAMES = [\n",
    "    \"class_of_worker\",\n",
    "    \"detailed_industry_recode\",\n",
    "    \"detailed_occupation_recode\",\n",
    "    \"education\",\n",
    "    \"enroll_in_edu_inst_last_wk\",\n",
    "    \"marital_stat\",\n",
    "    \"major_industry_code\",\n",
    "    \"major_occupation_code\",\n",
    "    \"race\",\n",
    "    \"hispanic_origin\",\n",
    "    \"sex\",\n",
    "    \"member_of_a_labor_union\",\n",
    "    \"reason_for_unemployment\",\n",
    "    \"full_or_part_time_employment_stat\",\n",
    "    \"tax_filer_stat\",\n",
    "    \"region_of_previous_residence\",\n",
    "    \"state_of_previous_residence\",\n",
    "    \"detailed_household_and_family_stat\",\n",
    "    \"detailed_household_summary_in_household\",\n",
    "    \"migration_code-change_in_msa\",\n",
    "    \"migration_code-change_in_reg\",\n",
    "    \"migration_code-move_within_reg\",\n",
    "    \"live_in_this_house_1_year_ago\",\n",
    "    \"migration_prev_res_in_sunbelt\",\n",
    "    \"family_members_under_18\",\n",
    "    \"country_of_birth_father\",\n",
    "    \"country_of_birth_mother\",\n",
    "    \"country_of_birth_self\",\n",
    "    \"citizenship\",\n",
    "    \"own_business_or_self_employed\",\n",
    "    \"fill_inc_questionnaire_for_veteran's_admin\",\n",
    "    \"veterans_benefits\",\n",
    "    \"year\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d732b83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         - 50000.\n",
      "1         - 50000.\n",
      "2         - 50000.\n",
      "3         - 50000.\n",
      "4         - 50000.\n",
      "           ...    \n",
      "99757     - 50000.\n",
      "99758     - 50000.\n",
      "99759     - 50000.\n",
      "99760     - 50000.\n",
      "99761     - 50000.\n",
      "Name: income_level, Length: 99762, dtype: object\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "99757    0\n",
      "99758    0\n",
      "99759    0\n",
      "99760    0\n",
      "99761    0\n",
      "Name: income_level, Length: 99762, dtype: int64\n",
      "0         6\n",
      "1        37\n",
      "2         0\n",
      "3        29\n",
      "4         4\n",
      "         ..\n",
      "99757     0\n",
      "99758     8\n",
      "99759     1\n",
      "99760    45\n",
      "99761     0\n",
      "Name: detailed_industry_recode, Length: 99762, dtype: object\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "target label 을 [\" - 50000.\", \" 50000+.\"] 에서 [0, 1] 로 변경함\n",
    "Categorical 항목은 str 타입으로 변경: 1 -> '1'\n",
    "'''\n",
    "def prepare_dataframe(dataframe):\n",
    "    # convert the target labels from string to integer\n",
    "    try:\n",
    "        dataframe[TARGET_COLUMN_NAME] = dataframe[TARGET_COLUMN_NAME].map(TARGET_LABELS.index)\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "    # Cast the categorical features to string\n",
    "    for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "        dataframe[feature_name] = dataframe[feature_name].astype(str)\n",
    "\n",
    "# 변경 전\n",
    "print(test_data[TARGET_COLUMN_NAME])\n",
    "\n",
    "prepare_dataframe(train_data)\n",
    "prepare_dataframe(test_data)\n",
    "\n",
    "# 변경 후\n",
    "print(test_data[TARGET_COLUMN_NAME])\n",
    "print(test_data[\"detailed_industry_recode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56da2e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (199523, 42)\n",
      "Test data shape: (99762, 42)\n",
      "                                                                                    0  \\\n",
      "age                                                                                73   \n",
      "class_of_worker                                                       Not in universe   \n",
      "detailed_industry_recode                                                            0   \n",
      "detailed_occupation_recode                                                          0   \n",
      "education                                                        High school graduate   \n",
      "wage_per_hour                                                                       0   \n",
      "enroll_in_edu_inst_last_wk                                            Not in universe   \n",
      "marital_stat                                                                  Widowed   \n",
      "major_industry_code                                       Not in universe or children   \n",
      "major_occupation_code                                                 Not in universe   \n",
      "race                                                                            White   \n",
      "hispanic_origin                                                             All other   \n",
      "sex                                                                            Female   \n",
      "member_of_a_labor_union                                               Not in universe   \n",
      "reason_for_unemployment                                               Not in universe   \n",
      "full_or_part_time_employment_stat                                  Not in labor force   \n",
      "capital_gains                                                                       0   \n",
      "capital_losses                                                                      0   \n",
      "dividends_from_stocks                                                               0   \n",
      "tax_filer_stat                                                               Nonfiler   \n",
      "region_of_previous_residence                                          Not in universe   \n",
      "state_of_previous_residence                                           Not in universe   \n",
      "detailed_household_and_family_stat           Other Rel 18+ ever marr not in subfamily   \n",
      "detailed_household_summary_in_household                 Other relative of householder   \n",
      "instance_weight                                                               1700.09   \n",
      "migration_code-change_in_msa                                                        ?   \n",
      "migration_code-change_in_reg                                                        ?   \n",
      "migration_code-move_within_reg                                                      ?   \n",
      "live_in_this_house_1_year_ago                        Not in universe under 1 year old   \n",
      "migration_prev_res_in_sunbelt                                                       ?   \n",
      "num_persons_worked_for_employer                                                     0   \n",
      "family_members_under_18                                               Not in universe   \n",
      "country_of_birth_father                                                 United-States   \n",
      "country_of_birth_mother                                                 United-States   \n",
      "country_of_birth_self                                                   United-States   \n",
      "citizenship                                         Native- Born in the United States   \n",
      "own_business_or_self_employed                                                       0   \n",
      "fill_inc_questionnaire_for_veteran's_admin                            Not in universe   \n",
      "veterans_benefits                                                                   2   \n",
      "weeks_worked_in_year                                                                0   \n",
      "year                                                                               95   \n",
      "income_level                                                                        0   \n",
      "\n",
      "                                                                               1  \\\n",
      "age                                                                           58   \n",
      "class_of_worker                                   Self-employed-not incorporated   \n",
      "detailed_industry_recode                                                       4   \n",
      "detailed_occupation_recode                                                    34   \n",
      "education                                             Some college but no degree   \n",
      "wage_per_hour                                                                  0   \n",
      "enroll_in_edu_inst_last_wk                                       Not in universe   \n",
      "marital_stat                                                            Divorced   \n",
      "major_industry_code                                                 Construction   \n",
      "major_occupation_code                        Precision production craft & repair   \n",
      "race                                                                       White   \n",
      "hispanic_origin                                                        All other   \n",
      "sex                                                                         Male   \n",
      "member_of_a_labor_union                                          Not in universe   \n",
      "reason_for_unemployment                                          Not in universe   \n",
      "full_or_part_time_employment_stat                       Children or Armed Forces   \n",
      "capital_gains                                                                  0   \n",
      "capital_losses                                                                 0   \n",
      "dividends_from_stocks                                                          0   \n",
      "tax_filer_stat                                                 Head of household   \n",
      "region_of_previous_residence                                               South   \n",
      "state_of_previous_residence                                             Arkansas   \n",
      "detailed_household_and_family_stat                                   Householder   \n",
      "detailed_household_summary_in_household                              Householder   \n",
      "instance_weight                                                          1053.55   \n",
      "migration_code-change_in_msa                                          MSA to MSA   \n",
      "migration_code-change_in_reg                                         Same county   \n",
      "migration_code-move_within_reg                                       Same county   \n",
      "live_in_this_house_1_year_ago                                                 No   \n",
      "migration_prev_res_in_sunbelt                                                Yes   \n",
      "num_persons_worked_for_employer                                                1   \n",
      "family_members_under_18                                          Not in universe   \n",
      "country_of_birth_father                                            United-States   \n",
      "country_of_birth_mother                                            United-States   \n",
      "country_of_birth_self                                              United-States   \n",
      "citizenship                                    Native- Born in the United States   \n",
      "own_business_or_self_employed                                                  0   \n",
      "fill_inc_questionnaire_for_veteran's_admin                       Not in universe   \n",
      "veterans_benefits                                                              2   \n",
      "weeks_worked_in_year                                                          52   \n",
      "year                                                                          94   \n",
      "income_level                                                                   0   \n",
      "\n",
      "                                                                                   2  \\\n",
      "age                                                                               18   \n",
      "class_of_worker                                                      Not in universe   \n",
      "detailed_industry_recode                                                           0   \n",
      "detailed_occupation_recode                                                         0   \n",
      "education                                                                 10th grade   \n",
      "wage_per_hour                                                                      0   \n",
      "enroll_in_edu_inst_last_wk                                               High school   \n",
      "marital_stat                                                           Never married   \n",
      "major_industry_code                                      Not in universe or children   \n",
      "major_occupation_code                                                Not in universe   \n",
      "race                                                       Asian or Pacific Islander   \n",
      "hispanic_origin                                                            All other   \n",
      "sex                                                                           Female   \n",
      "member_of_a_labor_union                                              Not in universe   \n",
      "reason_for_unemployment                                              Not in universe   \n",
      "full_or_part_time_employment_stat                                 Not in labor force   \n",
      "capital_gains                                                                      0   \n",
      "capital_losses                                                                     0   \n",
      "dividends_from_stocks                                                              0   \n",
      "tax_filer_stat                                                              Nonfiler   \n",
      "region_of_previous_residence                                         Not in universe   \n",
      "state_of_previous_residence                                          Not in universe   \n",
      "detailed_household_and_family_stat           Child 18+ never marr Not in a subfamily   \n",
      "detailed_household_summary_in_household                            Child 18 or older   \n",
      "instance_weight                                                               991.95   \n",
      "migration_code-change_in_msa                                                       ?   \n",
      "migration_code-change_in_reg                                                       ?   \n",
      "migration_code-move_within_reg                                                     ?   \n",
      "live_in_this_house_1_year_ago                       Not in universe under 1 year old   \n",
      "migration_prev_res_in_sunbelt                                                      ?   \n",
      "num_persons_worked_for_employer                                                    0   \n",
      "family_members_under_18                                              Not in universe   \n",
      "country_of_birth_father                                                      Vietnam   \n",
      "country_of_birth_mother                                                      Vietnam   \n",
      "country_of_birth_self                                                        Vietnam   \n",
      "citizenship                                      Foreign born- Not a citizen of U S    \n",
      "own_business_or_self_employed                                                      0   \n",
      "fill_inc_questionnaire_for_veteran's_admin                           Not in universe   \n",
      "veterans_benefits                                                                  2   \n",
      "weeks_worked_in_year                                                               0   \n",
      "year                                                                              95   \n",
      "income_level                                                                       0   \n",
      "\n",
      "                                                                                 3  \\\n",
      "age                                                                              9   \n",
      "class_of_worker                                                    Not in universe   \n",
      "detailed_industry_recode                                                         0   \n",
      "detailed_occupation_recode                                                       0   \n",
      "education                                                                 Children   \n",
      "wage_per_hour                                                                    0   \n",
      "enroll_in_edu_inst_last_wk                                         Not in universe   \n",
      "marital_stat                                                         Never married   \n",
      "major_industry_code                                    Not in universe or children   \n",
      "major_occupation_code                                              Not in universe   \n",
      "race                                                                         White   \n",
      "hispanic_origin                                                          All other   \n",
      "sex                                                                         Female   \n",
      "member_of_a_labor_union                                            Not in universe   \n",
      "reason_for_unemployment                                            Not in universe   \n",
      "full_or_part_time_employment_stat                         Children or Armed Forces   \n",
      "capital_gains                                                                    0   \n",
      "capital_losses                                                                   0   \n",
      "dividends_from_stocks                                                            0   \n",
      "tax_filer_stat                                                            Nonfiler   \n",
      "region_of_previous_residence                                       Not in universe   \n",
      "state_of_previous_residence                                        Not in universe   \n",
      "detailed_household_and_family_stat           Child <18 never marr not in subfamily   \n",
      "detailed_household_summary_in_household               Child under 18 never married   \n",
      "instance_weight                                                            1758.14   \n",
      "migration_code-change_in_msa                                              Nonmover   \n",
      "migration_code-change_in_reg                                              Nonmover   \n",
      "migration_code-move_within_reg                                            Nonmover   \n",
      "live_in_this_house_1_year_ago                                                  Yes   \n",
      "migration_prev_res_in_sunbelt                                      Not in universe   \n",
      "num_persons_worked_for_employer                                                  0   \n",
      "family_members_under_18                                       Both parents present   \n",
      "country_of_birth_father                                              United-States   \n",
      "country_of_birth_mother                                              United-States   \n",
      "country_of_birth_self                                                United-States   \n",
      "citizenship                                      Native- Born in the United States   \n",
      "own_business_or_self_employed                                                    0   \n",
      "fill_inc_questionnaire_for_veteran's_admin                         Not in universe   \n",
      "veterans_benefits                                                                0   \n",
      "weeks_worked_in_year                                                             0   \n",
      "year                                                                            94   \n",
      "income_level                                                                     0   \n",
      "\n",
      "                                                                                 4  \n",
      "age                                                                             10  \n",
      "class_of_worker                                                    Not in universe  \n",
      "detailed_industry_recode                                                         0  \n",
      "detailed_occupation_recode                                                       0  \n",
      "education                                                                 Children  \n",
      "wage_per_hour                                                                    0  \n",
      "enroll_in_edu_inst_last_wk                                         Not in universe  \n",
      "marital_stat                                                         Never married  \n",
      "major_industry_code                                    Not in universe or children  \n",
      "major_occupation_code                                              Not in universe  \n",
      "race                                                                         White  \n",
      "hispanic_origin                                                          All other  \n",
      "sex                                                                         Female  \n",
      "member_of_a_labor_union                                            Not in universe  \n",
      "reason_for_unemployment                                            Not in universe  \n",
      "full_or_part_time_employment_stat                         Children or Armed Forces  \n",
      "capital_gains                                                                    0  \n",
      "capital_losses                                                                   0  \n",
      "dividends_from_stocks                                                            0  \n",
      "tax_filer_stat                                                            Nonfiler  \n",
      "region_of_previous_residence                                       Not in universe  \n",
      "state_of_previous_residence                                        Not in universe  \n",
      "detailed_household_and_family_stat           Child <18 never marr not in subfamily  \n",
      "detailed_household_summary_in_household               Child under 18 never married  \n",
      "instance_weight                                                            1069.16  \n",
      "migration_code-change_in_msa                                              Nonmover  \n",
      "migration_code-change_in_reg                                              Nonmover  \n",
      "migration_code-move_within_reg                                            Nonmover  \n",
      "live_in_this_house_1_year_ago                                                  Yes  \n",
      "migration_prev_res_in_sunbelt                                      Not in universe  \n",
      "num_persons_worked_for_employer                                                  0  \n",
      "family_members_under_18                                       Both parents present  \n",
      "country_of_birth_father                                              United-States  \n",
      "country_of_birth_mother                                              United-States  \n",
      "country_of_birth_self                                                United-States  \n",
      "citizenship                                      Native- Born in the United States  \n",
      "own_business_or_self_employed                                                    0  \n",
      "fill_inc_questionnaire_for_veteran's_admin                         Not in universe  \n",
      "veterans_benefits                                                                0  \n",
      "weeks_worked_in_year                                                             0  \n",
      "year                                                                            94  \n",
      "income_level                                                                     0  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(train_data.head().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8124896",
   "metadata": {},
   "source": [
    "### Configure hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b1aa088",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GBM 의 주요 하이퍼파라미터들\n",
    "'''\n",
    "# Maximum number of decision trees. The effective number of trained trees can be smaller if early stopping is enabled.\n",
    "NUM_TREES = 250\n",
    "# Minimum number of examples in a node.\n",
    "MIN_EXAMPLES = 6\n",
    "# Maximum depth of the tree. max_depth=1 means that all trees will be roots.\n",
    "MAX_DEPTH = 5\n",
    "# Ratio of the dataset (sampling without replacement) used to train individual trees for the random sampling method.\n",
    "SUBSAMPLE = 0.65\n",
    "# Control the sampling of the datasets used to train individual trees.\n",
    "SAMPLING_METHOD = \"RANDOM\"\n",
    "# Ratio of the training dataset used to monitor the training. Require to be >0 if early stopping is enabled.\n",
    "VALIDATION_RATIO = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25336c",
   "metadata": {},
   "source": [
    "### Implement a training and evaluation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5aefb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, train_data, test_data, num_epochs=1, batch_size=None):\n",
    "    '''\n",
    "    모델을 훈련시키고 평가, 3가지 실험에서 모두 사용됨.\n",
    "    pandas dataframe 에서 tf.data.Dataset 생성\n",
    "    모델 훈련(model.fit)\n",
    "    테스트셋으로 모델 평가\n",
    "    '''\n",
    "    # (inputs, targets, sample_weights)\n",
    "    train_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "        train_data, label=TARGET_COLUMN_NAME, weight=WEIGHT_COLUMN_NAME\n",
    "    )\n",
    "    test_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "        test_data, label=TARGET_COLUMN_NAME, weight=WEIGHT_COLUMN_NAME\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, epochs=num_epochs, batch_size=batch_size)\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b195f3bb",
   "metadata": {},
   "source": [
    "# Experiment 1: Decision Forests with raw features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0c248",
   "metadata": {},
   "source": [
    "###  Specify model input feature usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ac2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_feature_usages():\n",
    "    '''\n",
    "    feature 의 이름과 특성(numerical or categorical) 지정 -> tfdf.keras.FeatureUsage\n",
    "    GBM 모델 생성시 인자로 전달\n",
    "    '''\n",
    "    feature_usages = []\n",
    "\n",
    "    for feature_name in NUMERIC_FEATURE_NAMES:\n",
    "        feature_usage = tfdf.keras.FeatureUsage(\n",
    "            name=feature_name, semantic=tfdf.keras.FeatureSemantic.NUMERICAL\n",
    "        )\n",
    "        feature_usages.append(feature_usage)\n",
    "\n",
    "    for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "        feature_usage = tfdf.keras.FeatureUsage(\n",
    "            name=feature_name, semantic=tfdf.keras.FeatureSemantic.CATEGORICAL\n",
    "        )\n",
    "        feature_usages.append(feature_usage)\n",
    "\n",
    "    return feature_usages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8c710",
   "metadata": {},
   "source": [
    "### Create a Gradient Boosted Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2281b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gbt_model():\n",
    "    # See all the model parameters in https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/GradientBoostedTreesModel\n",
    "    gbt_model = tfdf.keras.GradientBoostedTreesModel(\n",
    "        features=specify_feature_usages(), # 입력 피쳐 지정\n",
    "        exclude_non_specified_features=True, \n",
    "        num_trees=NUM_TREES, # 트리 개수\n",
    "        max_depth=MAX_DEPTH, # 트리 최대 깊이\n",
    "        min_examples=MIN_EXAMPLES, # 노드에 들어갈 최소 샘플 개수, 그 이하일때는 분기하지 않음\n",
    "        subsample=SUBSAMPLE, # 개별 트리를 훈련하는데 사용하는 데이터셋의 비율\n",
    "        validation_ratio=VALIDATION_RATIO, # 훈련셋중에 모델 검증을 위해 사용할 데이터 비율, \n",
    "        task=tfdf.keras.Task.CLASSIFICATION,\n",
    "    )\n",
    "\n",
    "    gbt_model.compile(weighted_metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")])\n",
    "    return gbt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f00a6",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd1a9107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpmndwy_mm as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 12:41:04.874891: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-10-24 12:41:04.874934: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: BigBoy\n",
      "2022-10-24 12:41:04.874942: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: BigBoy\n",
      "2022-10-24 12:41:04.875070: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.73.5\n",
      "2022-10-24 12:41:04.875099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2022-10-24 12:41:04.875106: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.73.5\n",
      "2022-10-24 12:41:04.876573: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:08.103885. Found 199523 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:31.063814\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO kernel.cc:1176] Loading model from path /tmp/tmpmndwy_mm/model/ with prefix 9159fb4463da486c\n",
      "[INFO abstract_model.cc:1248] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO kernel.cc:1022] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f2ee6888b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f2ee6888b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f2ee6888b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model compiled.\n",
      "Test accuracy: 95.8%\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "gbt_model = create_gbt_model()\n",
    "\n",
    "# 훈련 및 평가 -> 95.8%\n",
    "run_experiment(gbt_model, train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4313b",
   "metadata": {},
   "source": [
    "### Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ea6ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (40):\n",
      "\tage\n",
      "\tcapital_gains\n",
      "\tcapital_losses\n",
      "\tcitizenship\n",
      "\tclass_of_worker\n",
      "\tcountry_of_birth_father\n",
      "\tcountry_of_birth_mother\n",
      "\tcountry_of_birth_self\n",
      "\tdetailed_household_and_family_stat\n",
      "\tdetailed_household_summary_in_household\n",
      "\tdetailed_industry_recode\n",
      "\tdetailed_occupation_recode\n",
      "\tdividends_from_stocks\n",
      "\teducation\n",
      "\tenroll_in_edu_inst_last_wk\n",
      "\tfamily_members_under_18\n",
      "\tfill_inc_questionnaire_for_veteran's_admin\n",
      "\tfull_or_part_time_employment_stat\n",
      "\thispanic_origin\n",
      "\tlive_in_this_house_1_year_ago\n",
      "\tmajor_industry_code\n",
      "\tmajor_occupation_code\n",
      "\tmarital_stat\n",
      "\tmember_of_a_labor_union\n",
      "\tmigration_code-change_in_msa\n",
      "\tmigration_code-change_in_reg\n",
      "\tmigration_code-move_within_reg\n",
      "\tmigration_prev_res_in_sunbelt\n",
      "\tnum_persons_worked_for_employer\n",
      "\town_business_or_self_employed\n",
      "\trace\n",
      "\treason_for_unemployment\n",
      "\tregion_of_previous_residence\n",
      "\tsex\n",
      "\tstate_of_previous_residence\n",
      "\ttax_filer_stat\n",
      "\tveterans_benefits\n",
      "\twage_per_hour\n",
      "\tweeks_worked_in_year\n",
      "\tyear\n",
      "\n",
      "Trained with weights\n",
      "\n",
      "Variable Importance: MEAN_MIN_DEPTH:\n",
      "    1.                 \"enroll_in_edu_inst_last_wk\"  3.942647 ################\n",
      "    2.                    \"family_members_under_18\"  3.942647 ################\n",
      "    3.              \"live_in_this_house_1_year_ago\"  3.942647 ################\n",
      "    4.               \"migration_code-change_in_msa\"  3.942647 ################\n",
      "    5.             \"migration_code-move_within_reg\"  3.942647 ################\n",
      "    6.                                       \"year\"  3.942647 ################\n",
      "    7.                                    \"__LABEL\"  3.942647 ################\n",
      "    8.                                  \"__WEIGHTS\"  3.942647 ################\n",
      "    9.                                \"citizenship\"  3.942137 ###############\n",
      "   10.    \"detailed_household_summary_in_household\"  3.942137 ###############\n",
      "   11.               \"region_of_previous_residence\"  3.942137 ###############\n",
      "   12.                          \"veterans_benefits\"  3.942137 ###############\n",
      "   13.              \"migration_prev_res_in_sunbelt\"  3.940135 ###############\n",
      "   14.               \"migration_code-change_in_reg\"  3.939926 ###############\n",
      "   15.                      \"major_occupation_code\"  3.937681 ###############\n",
      "   16.                        \"major_industry_code\"  3.933687 ###############\n",
      "   17.                    \"reason_for_unemployment\"  3.926320 ###############\n",
      "   18.                            \"hispanic_origin\"  3.900776 ###############\n",
      "   19.                    \"member_of_a_labor_union\"  3.894843 ###############\n",
      "   20.                                       \"race\"  3.878617 ###############\n",
      "   21.            \"num_persons_worked_for_employer\"  3.818566 ##############\n",
      "   22.                               \"marital_stat\"  3.795667 ##############\n",
      "   23.          \"full_or_part_time_employment_stat\"  3.795431 ##############\n",
      "   24.                    \"country_of_birth_mother\"  3.787967 ##############\n",
      "   25.                             \"tax_filer_stat\"  3.784505 ##############\n",
      "   26. \"fill_inc_questionnaire_for_veteran's_admin\"  3.783607 ##############\n",
      "   27.              \"own_business_or_self_employed\"  3.776398 ##############\n",
      "   28.                    \"country_of_birth_father\"  3.715252 #############\n",
      "   29.                                        \"sex\"  3.708745 #############\n",
      "   30.                            \"class_of_worker\"  3.688424 #############\n",
      "   31.                       \"weeks_worked_in_year\"  3.665290 #############\n",
      "   32.                \"state_of_previous_residence\"  3.657234 #############\n",
      "   33.                      \"country_of_birth_self\"  3.654377 #############\n",
      "   34.                                        \"age\"  3.634295 ############\n",
      "   35.                              \"wage_per_hour\"  3.617817 ############\n",
      "   36.         \"detailed_household_and_family_stat\"  3.594743 ############\n",
      "   37.                             \"capital_losses\"  3.439298 ##########\n",
      "   38.                      \"dividends_from_stocks\"  3.423652 ##########\n",
      "   39.                              \"capital_gains\"  3.222753 ########\n",
      "   40.                                  \"education\"  3.158698 ########\n",
      "   41.                   \"detailed_industry_recode\"  2.981471 ######\n",
      "   42.                 \"detailed_occupation_recode\"  2.364817 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1.                                  \"education\" 33.000000 ################\n",
      "    2.                              \"capital_gains\" 29.000000 ##############\n",
      "    3.                             \"capital_losses\" 24.000000 ###########\n",
      "    4.         \"detailed_household_and_family_stat\" 14.000000 ######\n",
      "    5.                      \"dividends_from_stocks\" 14.000000 ######\n",
      "    6.                              \"wage_per_hour\" 12.000000 #####\n",
      "    7.                      \"country_of_birth_self\" 11.000000 #####\n",
      "    8.                 \"detailed_occupation_recode\" 11.000000 #####\n",
      "    9.                       \"weeks_worked_in_year\" 11.000000 #####\n",
      "   10.                                        \"age\" 10.000000 ####\n",
      "   11.                \"state_of_previous_residence\" 10.000000 ####\n",
      "   12. \"fill_inc_questionnaire_for_veteran's_admin\"  9.000000 ####\n",
      "   13.                            \"class_of_worker\"  8.000000 ###\n",
      "   14.          \"full_or_part_time_employment_stat\"  8.000000 ###\n",
      "   15.                               \"marital_stat\"  8.000000 ###\n",
      "   16.              \"own_business_or_self_employed\"  8.000000 ###\n",
      "   17.                                        \"sex\"  6.000000 ##\n",
      "   18.                             \"tax_filer_stat\"  5.000000 ##\n",
      "   19.                    \"country_of_birth_father\"  4.000000 #\n",
      "   20.                                       \"race\"  3.000000 #\n",
      "   21.                   \"detailed_industry_recode\"  2.000000 \n",
      "   22.                            \"hispanic_origin\"  2.000000 \n",
      "   23.                    \"country_of_birth_mother\"  1.000000 \n",
      "   24.            \"num_persons_worked_for_employer\"  1.000000 \n",
      "   25.                    \"reason_for_unemployment\"  1.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.                 \"detailed_occupation_recode\" 785.000000 ################\n",
      "    2.                   \"detailed_industry_recode\" 668.000000 #############\n",
      "    3.                              \"capital_gains\" 275.000000 #####\n",
      "    4.                      \"dividends_from_stocks\" 220.000000 ####\n",
      "    5.                             \"capital_losses\" 197.000000 ####\n",
      "    6.                                  \"education\" 178.000000 ###\n",
      "    7.                    \"country_of_birth_mother\" 128.000000 ##\n",
      "    8.                    \"country_of_birth_father\" 116.000000 ##\n",
      "    9.                                        \"age\" 114.000000 ##\n",
      "   10.                              \"wage_per_hour\" 98.000000 #\n",
      "   11.                \"state_of_previous_residence\" 95.000000 #\n",
      "   12.         \"detailed_household_and_family_stat\" 78.000000 #\n",
      "   13.                            \"class_of_worker\" 67.000000 #\n",
      "   14.                      \"country_of_birth_self\" 65.000000 #\n",
      "   15.                                        \"sex\" 65.000000 #\n",
      "   16.                       \"weeks_worked_in_year\" 60.000000 #\n",
      "   17.                             \"tax_filer_stat\" 57.000000 #\n",
      "   18.            \"num_persons_worked_for_employer\" 54.000000 #\n",
      "   19.              \"own_business_or_self_employed\" 30.000000 \n",
      "   20.                               \"marital_stat\" 26.000000 \n",
      "   21.                    \"member_of_a_labor_union\" 16.000000 \n",
      "   22. \"fill_inc_questionnaire_for_veteran's_admin\" 15.000000 \n",
      "   23.          \"full_or_part_time_employment_stat\" 15.000000 \n",
      "   24.                        \"major_industry_code\" 15.000000 \n",
      "   25.                            \"hispanic_origin\"  9.000000 \n",
      "   26.                      \"major_occupation_code\"  7.000000 \n",
      "   27.                                       \"race\"  7.000000 \n",
      "   28.                                \"citizenship\"  1.000000 \n",
      "   29.    \"detailed_household_summary_in_household\"  1.000000 \n",
      "   30.               \"migration_code-change_in_reg\"  1.000000 \n",
      "   31.              \"migration_prev_res_in_sunbelt\"  1.000000 \n",
      "   32.                    \"reason_for_unemployment\"  1.000000 \n",
      "   33.               \"region_of_previous_residence\"  1.000000 \n",
      "   34.                          \"veterans_benefits\"  1.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.                 \"detailed_occupation_recode\" 15392441.075369 ################\n",
      "    2.                              \"capital_gains\" 5277826.822514 #####\n",
      "    3.                                  \"education\" 4751749.289550 ####\n",
      "    4.                      \"dividends_from_stocks\" 3792002.951255 ###\n",
      "    5.                   \"detailed_industry_recode\" 2882200.882109 ##\n",
      "    6.                                        \"sex\" 2559417.877325 ##\n",
      "    7.                                        \"age\" 2042990.944829 ##\n",
      "    8.                             \"capital_losses\" 1735728.772551 #\n",
      "    9.                       \"weeks_worked_in_year\" 1272820.203971 #\n",
      "   10.                             \"tax_filer_stat\" 697890.160846 \n",
      "   11.            \"num_persons_worked_for_employer\" 671351.905595 \n",
      "   12.         \"detailed_household_and_family_stat\" 444620.829557 \n",
      "   13.                            \"class_of_worker\" 362250.565331 \n",
      "   14.                    \"country_of_birth_mother\" 296311.574426 \n",
      "   15.                    \"country_of_birth_father\" 258198.889206 \n",
      "   16.                              \"wage_per_hour\" 239764.219048 \n",
      "   17.                \"state_of_previous_residence\" 237687.602572 \n",
      "   18.                      \"country_of_birth_self\" 103002.168158 \n",
      "   19.                               \"marital_stat\" 102449.735314 \n",
      "   20.              \"own_business_or_self_employed\" 82938.893541 \n",
      "   21. \"fill_inc_questionnaire_for_veteran's_admin\" 22692.700206 \n",
      "   22.          \"full_or_part_time_employment_stat\" 19078.398837 \n",
      "   23.                        \"major_industry_code\" 18450.345505 \n",
      "   24.                    \"member_of_a_labor_union\" 14905.360879 \n",
      "   25.                            \"hispanic_origin\" 12602.867902 \n",
      "   26.                      \"major_occupation_code\" 8709.665989 \n",
      "   27.                                       \"race\" 6116.282065 \n",
      "   28.                                \"citizenship\" 3291.490393 \n",
      "   29.    \"detailed_household_summary_in_household\" 2733.439375 \n",
      "   30.                          \"veterans_benefits\" 1230.940488 \n",
      "   31.               \"region_of_previous_residence\" 1139.240981 \n",
      "   32.                    \"reason_for_unemployment\" 219.245124 \n",
      "   33.               \"migration_code-change_in_reg\" 55.806436 \n",
      "   34.              \"migration_prev_res_in_sunbelt\" 37.780635 \n",
      "\n",
      "\n",
      "\n",
      "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 0.228983\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 245\n",
      "Total number of nodes: 7179\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 245 Average: 29.302 StdDev: 2.96211\n",
      "Min: 17 Max: 31 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 17, 18)   2   0.82%   0.82%\n",
      "[ 18, 19)   0   0.00%   0.82%\n",
      "[ 19, 20)   3   1.22%   2.04%\n",
      "[ 20, 21)   0   0.00%   2.04%\n",
      "[ 21, 22)   4   1.63%   3.67%\n",
      "[ 22, 23)   0   0.00%   3.67%\n",
      "[ 23, 24)  15   6.12%   9.80% #\n",
      "[ 24, 25)   0   0.00%   9.80%\n",
      "[ 25, 26)   5   2.04%  11.84%\n",
      "[ 26, 27)   0   0.00%  11.84%\n",
      "[ 27, 28)  21   8.57%  20.41% #\n",
      "[ 28, 29)   0   0.00%  20.41%\n",
      "[ 29, 30)  39  15.92%  36.33% ###\n",
      "[ 30, 31)   0   0.00%  36.33%\n",
      "[ 31, 31] 156  63.67% 100.00% ##########\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 3712 Average: 3.95259 StdDev: 0.249814\n",
      "Min: 2 Max: 4 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 2, 3)   32   0.86%   0.86%\n",
      "[ 3, 4)  112   3.02%   3.88%\n",
      "[ 4, 4] 3568  96.12% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 3712 Average: 11849.3 StdDev: 33719.3\n",
      "Min: 6 Max: 179360 Ignored: 0\n",
      "----------------------------------------------\n",
      "[      6,   8973) 3100  83.51%  83.51% ##########\n",
      "[   8973,  17941)  148   3.99%  87.50%\n",
      "[  17941,  26909)   79   2.13%  89.63%\n",
      "[  26909,  35877)   36   0.97%  90.60%\n",
      "[  35877,  44844)   44   1.19%  91.78%\n",
      "[  44844,  53812)   17   0.46%  92.24%\n",
      "[  53812,  62780)   20   0.54%  92.78%\n",
      "[  62780,  71748)   39   1.05%  93.83%\n",
      "[  71748,  80715)   24   0.65%  94.48%\n",
      "[  80715,  89683)   12   0.32%  94.80%\n",
      "[  89683,  98651)   22   0.59%  95.39%\n",
      "[  98651, 107619)   21   0.57%  95.96%\n",
      "[ 107619, 116586)   17   0.46%  96.42%\n",
      "[ 116586, 125554)   17   0.46%  96.88%\n",
      "[ 125554, 134522)   13   0.35%  97.23%\n",
      "[ 134522, 143490)    8   0.22%  97.44%\n",
      "[ 143490, 152457)    5   0.13%  97.58%\n",
      "[ 152457, 161425)    6   0.16%  97.74%\n",
      "[ 161425, 170393)   15   0.40%  98.14%\n",
      "[ 170393, 179360]   69   1.86% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t785 : detailed_occupation_recode [CATEGORICAL]\n",
      "\t668 : detailed_industry_recode [CATEGORICAL]\n",
      "\t275 : capital_gains [NUMERICAL]\n",
      "\t220 : dividends_from_stocks [NUMERICAL]\n",
      "\t197 : capital_losses [NUMERICAL]\n",
      "\t178 : education [CATEGORICAL]\n",
      "\t128 : country_of_birth_mother [CATEGORICAL]\n",
      "\t116 : country_of_birth_father [CATEGORICAL]\n",
      "\t114 : age [NUMERICAL]\n",
      "\t98 : wage_per_hour [NUMERICAL]\n",
      "\t95 : state_of_previous_residence [CATEGORICAL]\n",
      "\t78 : detailed_household_and_family_stat [CATEGORICAL]\n",
      "\t67 : class_of_worker [CATEGORICAL]\n",
      "\t65 : sex [CATEGORICAL]\n",
      "\t65 : country_of_birth_self [CATEGORICAL]\n",
      "\t60 : weeks_worked_in_year [NUMERICAL]\n",
      "\t57 : tax_filer_stat [CATEGORICAL]\n",
      "\t54 : num_persons_worked_for_employer [NUMERICAL]\n",
      "\t30 : own_business_or_self_employed [CATEGORICAL]\n",
      "\t26 : marital_stat [CATEGORICAL]\n",
      "\t16 : member_of_a_labor_union [CATEGORICAL]\n",
      "\t15 : major_industry_code [CATEGORICAL]\n",
      "\t15 : full_or_part_time_employment_stat [CATEGORICAL]\n",
      "\t15 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
      "\t9 : hispanic_origin [CATEGORICAL]\n",
      "\t7 : race [CATEGORICAL]\n",
      "\t7 : major_occupation_code [CATEGORICAL]\n",
      "\t1 : veterans_benefits [CATEGORICAL]\n",
      "\t1 : region_of_previous_residence [CATEGORICAL]\n",
      "\t1 : reason_for_unemployment [CATEGORICAL]\n",
      "\t1 : migration_prev_res_in_sunbelt [CATEGORICAL]\n",
      "\t1 : migration_code-change_in_reg [CATEGORICAL]\n",
      "\t1 : detailed_household_summary_in_household [CATEGORICAL]\n",
      "\t1 : citizenship [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t33 : education [CATEGORICAL]\n",
      "\t29 : capital_gains [NUMERICAL]\n",
      "\t24 : capital_losses [NUMERICAL]\n",
      "\t14 : dividends_from_stocks [NUMERICAL]\n",
      "\t14 : detailed_household_and_family_stat [CATEGORICAL]\n",
      "\t12 : wage_per_hour [NUMERICAL]\n",
      "\t11 : weeks_worked_in_year [NUMERICAL]\n",
      "\t11 : detailed_occupation_recode [CATEGORICAL]\n",
      "\t11 : country_of_birth_self [CATEGORICAL]\n",
      "\t10 : state_of_previous_residence [CATEGORICAL]\n",
      "\t10 : age [NUMERICAL]\n",
      "\t9 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
      "\t8 : own_business_or_self_employed [CATEGORICAL]\n",
      "\t8 : marital_stat [CATEGORICAL]\n",
      "\t8 : full_or_part_time_employment_stat [CATEGORICAL]\n",
      "\t8 : class_of_worker [CATEGORICAL]\n",
      "\t6 : sex [CATEGORICAL]\n",
      "\t5 : tax_filer_stat [CATEGORICAL]\n",
      "\t4 : country_of_birth_father [CATEGORICAL]\n",
      "\t3 : race [CATEGORICAL]\n",
      "\t2 : hispanic_origin [CATEGORICAL]\n",
      "\t2 : detailed_industry_recode [CATEGORICAL]\n",
      "\t1 : reason_for_unemployment [CATEGORICAL]\n",
      "\t1 : num_persons_worked_for_employer [NUMERICAL]\n",
      "\t1 : country_of_birth_mother [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t140 : detailed_occupation_recode [CATEGORICAL]\n",
      "\t82 : capital_gains [NUMERICAL]\n",
      "\t65 : capital_losses [NUMERICAL]\n",
      "\t62 : education [CATEGORICAL]\n",
      "\t59 : detailed_industry_recode [CATEGORICAL]\n",
      "\t47 : dividends_from_stocks [NUMERICAL]\n",
      "\t31 : wage_per_hour [NUMERICAL]\n",
      "\t26 : detailed_household_and_family_stat [CATEGORICAL]\n",
      "\t23 : age [NUMERICAL]\n",
      "\t22 : state_of_previous_residence [CATEGORICAL]\n",
      "\t21 : country_of_birth_self [CATEGORICAL]\n",
      "\t21 : class_of_worker [CATEGORICAL]\n",
      "\t20 : weeks_worked_in_year [NUMERICAL]\n",
      "\t20 : sex [CATEGORICAL]\n",
      "\t15 : country_of_birth_father [CATEGORICAL]\n",
      "\t12 : own_business_or_self_employed [CATEGORICAL]\n",
      "\t11 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
      "\t10 : num_persons_worked_for_employer [NUMERICAL]\n",
      "\t9 : tax_filer_stat [CATEGORICAL]\n",
      "\t9 : full_or_part_time_employment_stat [CATEGORICAL]\n",
      "\t8 : marital_stat [CATEGORICAL]\n",
      "\t8 : country_of_birth_mother [CATEGORICAL]\n",
      "\t6 : member_of_a_labor_union [CATEGORICAL]\n",
      "\t5 : race [CATEGORICAL]\n",
      "\t2 : hispanic_origin [CATEGORICAL]\n",
      "\t1 : reason_for_unemployment [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t399 : detailed_occupation_recode [CATEGORICAL]\n",
      "\t249 : detailed_industry_recode [CATEGORICAL]\n",
      "\t170 : capital_gains [NUMERICAL]\n",
      "\t117 : dividends_from_stocks [NUMERICAL]\n",
      "\t116 : capital_losses [NUMERICAL]\n",
      "\t87 : education [CATEGORICAL]\n",
      "\t59 : wage_per_hour [NUMERICAL]\n",
      "\t45 : detailed_household_and_family_stat [CATEGORICAL]\n",
      "\t43 : country_of_birth_father [CATEGORICAL]\n",
      "\t43 : age [NUMERICAL]\n",
      "\t40 : country_of_birth_self [CATEGORICAL]\n",
      "\t38 : state_of_previous_residence [CATEGORICAL]\n",
      "\t38 : class_of_worker [CATEGORICAL]\n",
      "\t37 : sex [CATEGORICAL]\n",
      "\t36 : weeks_worked_in_year [NUMERICAL]\n",
      "\t33 : country_of_birth_mother [CATEGORICAL]\n",
      "\t28 : num_persons_worked_for_employer [NUMERICAL]\n",
      "\t26 : tax_filer_stat [CATEGORICAL]\n",
      "\t14 : own_business_or_self_employed [CATEGORICAL]\n",
      "\t14 : marital_stat [CATEGORICAL]\n",
      "\t12 : full_or_part_time_employment_stat [CATEGORICAL]\n",
      "\t12 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
      "\t8 : member_of_a_labor_union [CATEGORICAL]\n",
      "\t6 : race [CATEGORICAL]\n",
      "\t6 : hispanic_origin [CATEGORICAL]\n",
      "\t2 : major_occupation_code [CATEGORICAL]\n",
      "\t2 : major_industry_code [CATEGORICAL]\n",
      "\t1 : reason_for_unemployment [CATEGORICAL]\n",
      "\t1 : migration_prev_res_in_sunbelt [CATEGORICAL]\n",
      "\t1 : migration_code-change_in_reg [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t785 : detailed_occupation_recode [CATEGORICAL]\n",
      "\t668 : detailed_industry_recode [CATEGORICAL]\n",
      "\t275 : capital_gains [NUMERICAL]\n",
      "\t220 : dividends_from_stocks [NUMERICAL]\n",
      "\t197 : capital_losses [NUMERICAL]\n",
      "\t178 : education [CATEGORICAL]\n",
      "\t128 : country_of_birth_mother [CATEGORICAL]\n",
      "\t116 : country_of_birth_father [CATEGORICAL]\n",
      "\t114 : age [NUMERICAL]\n",
      "\t98 : wage_per_hour [NUMERICAL]\n",
      "\t95 : state_of_previous_residence [CATEGORICAL]\n",
      "\t78 : detailed_household_and_family_stat [CATEGORICAL]\n",
      "\t67 : class_of_worker [CATEGORICAL]\n",
      "\t65 : sex [CATEGORICAL]\n",
      "\t65 : country_of_birth_self [CATEGORICAL]\n",
      "\t60 : weeks_worked_in_year [NUMERICAL]\n",
      "\t57 : tax_filer_stat [CATEGORICAL]\n",
      "\t54 : num_persons_worked_for_employer [NUMERICAL]\n",
      "\t30 : own_business_or_self_employed [CATEGORICAL]\n",
      "\t26 : marital_stat [CATEGORICAL]\n",
      "\t16 : member_of_a_labor_union [CATEGORICAL]\n",
      "\t15 : major_industry_code [CATEGORICAL]\n",
      "\t15 : full_or_part_time_employment_stat [CATEGORICAL]\n",
      "\t15 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
      "\t9 : hispanic_origin [CATEGORICAL]\n",
      "\t7 : race [CATEGORICAL]\n",
      "\t7 : major_occupation_code [CATEGORICAL]\n",
      "\t1 : veterans_benefits [CATEGORICAL]\n",
      "\t1 : region_of_previous_residence [CATEGORICAL]\n",
      "\t1 : reason_for_unemployment [CATEGORICAL]\n",
      "\t1 : migration_prev_res_in_sunbelt [CATEGORICAL]\n",
      "\t1 : migration_code-change_in_reg [CATEGORICAL]\n",
      "\t1 : detailed_household_summary_in_household [CATEGORICAL]\n",
      "\t1 : citizenship [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t785 : detailed_occupation_recode [CATEGORICAL]\n",
      "\t668 : detailed_industry_recode [CATEGORICAL]\n",
      "\t275 : capital_gains [NUMERICAL]\n",
      "\t220 : dividends_from_stocks [NUMERICAL]\n",
      "\t197 : capital_losses [NUMERICAL]\n",
      "\t178 : education [CATEGORICAL]\n",
      "\t128 : country_of_birth_mother [CATEGORICAL]\n",
      "\t116 : country_of_birth_father [CATEGORICAL]\n",
      "\t114 : age [NUMERICAL]\n",
      "\t98 : wage_per_hour [NUMERICAL]\n",
      "\t95 : state_of_previous_residence [CATEGORICAL]\n",
      "\t78 : detailed_household_and_family_stat [CATEGORICAL]\n",
      "\t67 : class_of_worker [CATEGORICAL]\n",
      "\t65 : sex [CATEGORICAL]\n",
      "\t65 : country_of_birth_self [CATEGORICAL]\n",
      "\t60 : weeks_worked_in_year [NUMERICAL]\n",
      "\t57 : tax_filer_stat [CATEGORICAL]\n",
      "\t54 : num_persons_worked_for_employer [NUMERICAL]\n",
      "\t30 : own_business_or_self_employed [CATEGORICAL]\n",
      "\t26 : marital_stat [CATEGORICAL]\n",
      "\t16 : member_of_a_labor_union [CATEGORICAL]\n",
      "\t15 : major_industry_code [CATEGORICAL]\n",
      "\t15 : full_or_part_time_employment_stat [CATEGORICAL]\n",
      "\t15 : fill_inc_questionnaire_for_veteran's_admin [CATEGORICAL]\n",
      "\t9 : hispanic_origin [CATEGORICAL]\n",
      "\t7 : race [CATEGORICAL]\n",
      "\t7 : major_occupation_code [CATEGORICAL]\n",
      "\t1 : veterans_benefits [CATEGORICAL]\n",
      "\t1 : region_of_previous_residence [CATEGORICAL]\n",
      "\t1 : reason_for_unemployment [CATEGORICAL]\n",
      "\t1 : migration_prev_res_in_sunbelt [CATEGORICAL]\n",
      "\t1 : migration_code-change_in_reg [CATEGORICAL]\n",
      "\t1 : detailed_household_summary_in_household [CATEGORICAL]\n",
      "\t1 : citizenship [CATEGORICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t2418 : ContainsBitmapCondition\n",
      "\t1018 : HigherCondition\n",
      "\t31 : ContainsCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t137 : ContainsBitmapCondition\n",
      "\t101 : HigherCondition\n",
      "\t7 : ContainsCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t448 : ContainsBitmapCondition\n",
      "\t278 : HigherCondition\n",
      "\t9 : ContainsCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t1097 : ContainsBitmapCondition\n",
      "\t569 : HigherCondition\n",
      "\t17 : ContainsCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t2418 : ContainsBitmapCondition\n",
      "\t1018 : HigherCondition\n",
      "\t31 : ContainsCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t2418 : ContainsBitmapCondition\n",
      "\t1018 : HigherCondition\n",
      "\t31 : ContainsCondition\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(gbt_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01248e45",
   "metadata": {},
   "source": [
    "# Experiment 2: Decision Forests with target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257a349",
   "metadata": {},
   "source": [
    "### Implement Binary Target Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd266ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Target 이 아니라 Categorical feature 를 인코딩함\n",
    "feature value 에 대한 (positive_frequency, negative_frequency, positive_probability) 로 인코딩\n",
    "positive_probability = pos_freq / (pos_freq + neg_freq + correction)\n",
    "'''\n",
    "\n",
    "class BinaryTargetEncoding(layers.Layer):\n",
    "    def __init__(self, vocabulary_size=None, correction=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.correction = correction\n",
    "        \n",
    "    def adapt(self, data):\n",
    "        '''\n",
    "        data is expected to be an integer numpy array to a Tensor shape [num_examples, 2].\n",
    "        This contains feature falues for a given feature in the dataset, and target values.\n",
    "        '''\n",
    "        # convert the data to a tensor\n",
    "        data = tf.convert_to_tensor(data)\n",
    "        # Separate the feature values and target values\n",
    "        feature_values = tf.cast(data[:,0], tf.dtypes.int32)\n",
    "        target_values = tf.cast(data[:,1], tf.dtypes.bool)\n",
    "        \n",
    "        # Compute the vocabulary_size of not specified\n",
    "        if self.vocabulary_size is None:\n",
    "            self.vocabulary_size = tf.unique(feature_values).y.shape[0]\n",
    "            \n",
    "        # Filter the data where the target label is positive.\n",
    "        positive_indices = tf.where(condition=target_values)\n",
    "        positive_feature_values = tf.gather_nd(params=feature_values, indices=positive_indices)\n",
    "        \n",
    "        # Compute how many times each feature value occurred with a positive target label.\n",
    "        positive_frequency = tf.math.unsorted_segment_sum(\n",
    "            data = tf.ones(shape=(positive_feature_values.shape[0], 1)),\n",
    "            segment_ids=positive_feature_values,\n",
    "            num_segments=self.vocabulary_size,\n",
    "        )\n",
    "                         \n",
    "        # Filter the data where the target label is negative.\n",
    "        negative_indices = tf.where(condition=tf.math.logical_not(target_values))\n",
    "        negative_feature_values = tf.gather_nd(\n",
    "            params=feature_values, indices=negative_indices\n",
    "        )\n",
    "        # Compute how many times each feature value occurred with a negative target label.\n",
    "        negative_frequency = tf.math.unsorted_segment_sum(\n",
    "            data=tf.ones(\n",
    "                shape=(negative_feature_values.shape[0], 1)),\n",
    "            segment_ids=negative_feature_values,\n",
    "            num_segments=self.vocabulary_size,\n",
    "        )\n",
    "        # Compute positive probability for the input feature values.\n",
    "        positive_probability = positive_frequency / (\n",
    "            positive_frequency + negative_frequency + self.correction\n",
    "        )\n",
    "        # Concatenate the computed statistics for traget_encoding.\n",
    "        target_encoding_statistics = tf.cast(\n",
    "            tf.concat(\n",
    "                [positive_frequency, negative_frequency, positive_probability], axis=1\n",
    "            ),\n",
    "            dtype=tf.dtypes.float32,\n",
    "        )\n",
    "        self.target_encoding_statistics = tf.constant(target_encoding_statistics)\n",
    "        print('** target_encoding_statics **\\n', self.target_encoding_statistics)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "        inputs is expected to be an integer numpy array to a Tensor shape [num_examples, 1].\n",
    "        This includes the feature values for a given feature in the dataset.\n",
    "        '''\n",
    "        if self.target_encoding_statistics == None:\n",
    "            raise ValueError(f'You need to call the adapt method to compute target encoding statistics')\n",
    "            \n",
    "        # Convert the inputs to a tensor\n",
    "        inputs = tf.convert_to_tensor(inputs)\n",
    "        # Cast the inputs int64 a tensor\n",
    "        inputs = tf.cast(inputs, tf.dtypes.int64)\n",
    "        # Lookup target encoding statistics for the input feature values.\n",
    "        target_encoding_statistics = tf.cast(\n",
    "            tf.gather_nd(self.target_encoding_statistics, inputs), \n",
    "            dtype=tf.dtypes.float32)\n",
    "        return target_encoding_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a54619d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[6.         0.         0.85714287]\n",
      " [4.         3.         0.5       ]\n",
      " [1.         5.         0.14285715]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[6.         0.         0.85714287]\n",
      " [4.         3.         0.5       ]\n",
      " [1.         5.         0.14285715]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data = tf.constant(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [2, 0],\n",
    "        [0, 1],\n",
    "        [1, 1],\n",
    "        [1, 1],\n",
    "        [2, 0],\n",
    "        [1, 0],\n",
    "        [0, 1],\n",
    "        [2, 1],\n",
    "        [1, 0],\n",
    "        [0, 1],\n",
    "        [2, 0],\n",
    "        [0, 1],\n",
    "        [1, 1],\n",
    "        [1, 1],\n",
    "        [2, 0],\n",
    "        [1, 0],\n",
    "        [0, 1],\n",
    "        [2, 0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "binary_target_encoder = BinaryTargetEncoding()\n",
    "binary_target_encoder.adapt(data)\n",
    "print(binary_target_encoder([[0], [1], [2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555294b",
   "metadata": {},
   "source": [
    "### Create model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae49468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "target_encoder 에 대한 keras Input layer\n",
    "'''\n",
    "def create_model_inputs():\n",
    "    inputs = {}    \n",
    "    for feature_name in NUMERIC_FEATURE_NAMES:\n",
    "        inputs[feature_name] = layers.Input(name=feature_name, shape=(), dtype=tf.float32)\n",
    "    for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "        inputs[feature_name] = layers.Input(name=feature_name, shape=(), dtype=tf.string)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14f264c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "BinaryTargetEncodeing 을 이용해서 feature encoding 하는 keras Model 생성\n",
    "'''\n",
    "\n",
    "def create_target_encoder():\n",
    "    inputs = create_model_inputs()\n",
    "    target_values = train_data[[TARGET_COLUMN_NAME]].to_numpy()\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            # Get the vocabulary of the categorical feature. Sorted list of unique values\n",
    "            vocabulary = sorted(\n",
    "                [str(value) for value in list(train_data[feature_name].unique())]\n",
    "            )\n",
    "            print(feature_name, 'vocabulary', vocabulary)\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            lookup = layers.StringLookup(\n",
    "                vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
    "            )\n",
    "            print('lookup', lookup)\n",
    "            # Convert the string input values into integer indices.\n",
    "            value_indices = lookup(inputs[feature_name])\n",
    "            # Prepare the data to adapt the target encoding.\n",
    "            print(\"### Adapting target encoding for:\", feature_name)\n",
    "            feature_values = train_data[[feature_name]].to_numpy().astype(str)\n",
    "            feature_value_indices = lookup(feature_values)\n",
    "            data = tf.concat([feature_value_indices, target_values], axis=1)\n",
    "            feature_encoder = BinaryTargetEncoding()\n",
    "            feature_encoder.adapt(data)\n",
    "            # Convert the feature value indices to target encoding representations.\n",
    "            encoded_feature = feature_encoder(tf.expand_dims(value_indices, -1))\n",
    "        else:\n",
    "            # Expand the dimensions of the numerical input feature and use it as-is.\n",
    "            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "        # Add the encoded feature to the list.\n",
    "        encoded_features.append(encoded_feature)\n",
    "    # Concatenate all the encoded features.\n",
    "    encoded_features = tf.concat(encoded_features, axis=1)\n",
    "    # Create and return a Keras model with encoded features as outputs.\n",
    "    return keras.Model(inputs=inputs, outputs=encoded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02017dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gbt_with_preprocessor(preprocessor):\n",
    "\n",
    "    gbt_model = tfdf.keras.GradientBoostedTreesModel(\n",
    "        preprocessing=preprocessor,  # Categorical feature 는 BinaryTargetEncoding 된 입력을 사용함\n",
    "        num_trees=NUM_TREES,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_examples=MIN_EXAMPLES,\n",
    "        subsample=SUBSAMPLE,\n",
    "        validation_ratio=VALIDATION_RATIO,\n",
    "        task=tfdf.keras.Task.CLASSIFICATION,\n",
    "    )\n",
    "\n",
    "    gbt_model.compile(metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")])\n",
    "\n",
    "    return gbt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48b1a193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_of_worker vocabulary [' Federal government', ' Local government', ' Never worked', ' Not in universe', ' Private', ' Self-employed-incorporated', ' Self-employed-not incorporated', ' State government', ' Without pay']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc1bec70>\n",
      "### Adapting target encoding for: class_of_worker\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[5.9700000e+02 2.3280000e+03 2.0403281e-01]\n",
      " [8.4700000e+02 6.9370000e+03 1.0879897e-01]\n",
      " [2.0000000e+00 4.3700000e+02 4.5454544e-03]\n",
      " [9.0400000e+02 9.9341000e+04 9.0178158e-03]\n",
      " [7.3220000e+03 6.4706000e+04 1.0165350e-01]\n",
      " [1.1340000e+03 2.1310000e+03 3.4721372e-01]\n",
      " [1.0900000e+03 7.3550000e+03 1.2905517e-01]\n",
      " [4.8500000e+02 3.7420000e+03 1.1471145e-01]\n",
      " [1.0000000e+00 1.6400000e+02 6.0240962e-03]], shape=(9, 3), dtype=float32)\n",
      "detailed_industry_recode vocabulary ['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '6', '7', '8', '9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc155850>\n",
      "### Adapting target encoding for: detailed_industry_recode\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[9.0600000e+02 9.9778000e+04 8.9983614e-03]\n",
      " [4.7000000e+01 7.8000000e+02 5.6763284e-02]\n",
      " [0.0000000e+00 4.0000000e+00 0.0000000e+00]\n",
      " [3.2400000e+02 1.4400000e+03 1.8356940e-01]\n",
      " [2.8100000e+02 1.0690000e+03 2.0799407e-01]\n",
      " [2.1200000e+02 6.8700000e+02 2.3555556e-01]\n",
      " [6.9000000e+01 2.2600000e+02 2.3310810e-01]\n",
      " [1.1500000e+02 3.3700000e+02 2.5386313e-01]\n",
      " [1.2100000e+02 4.1800000e+02 2.2407408e-01]\n",
      " [1.2000000e+01 1.4500000e+02 7.5949363e-02]\n",
      " [3.7000000e+01 4.4600000e+02 7.6446280e-02]\n",
      " [9.3000000e+01 1.2530000e+03 6.9042318e-02]\n",
      " [1.3100000e+02 2.0650000e+03 5.9626766e-02]\n",
      " [1.5000000e+01 1.7000000e+01 4.5454547e-01]\n",
      " [2.7000000e+01 5.3200000e+02 4.8214287e-02]\n",
      " [3.9000000e+01 9.1300000e+02 4.0923398e-02]\n",
      " [9.2000000e+01 4.3300000e+02 1.7490494e-01]\n",
      " [1.8000000e+02 1.3230000e+03 1.1968085e-01]\n",
      " [2.9400000e+02 7.9000000e+02 2.7096775e-01]\n",
      " [4.8000000e+01 7.9000000e+01 3.7500000e-01]\n",
      " [6.0000000e+01 5.6600000e+02 9.5693782e-02]\n",
      " [8.0000000e+00 1.3500000e+02 5.5555556e-02]\n",
      " [4.7600000e+02 3.7330000e+03 1.1306413e-01]\n",
      " [1.4600000e+02 4.1700000e+02 2.5886524e-01]\n",
      " [2.7000000e+02 9.1100000e+02 2.2842640e-01]\n",
      " [2.5600000e+02 9.2200000e+02 2.1713316e-01]\n",
      " [5.5200000e+02 3.0440000e+03 1.5346122e-01]\n",
      " [7.8900000e+02 1.6281000e+04 4.6218734e-02]\n",
      " [5.2600000e+02 2.2390000e+03 1.9016631e-01]\n",
      " [5.9300000e+02 2.7870000e+03 1.7539190e-01]\n",
      " [5.0000000e+00 9.4000000e+02 5.2854121e-03]\n",
      " [5.2000000e+02 3.5020000e+03 1.2925677e-01]\n",
      " [9.9000000e+01 1.5300000e+03 6.0736198e-02]\n",
      " [1.0500000e+02 2.8320000e+03 3.5738599e-02]\n",
      " [5.3300000e+02 5.4510000e+03 8.9055970e-02]\n",
      " [1.1300000e+02 1.5380000e+03 6.8401940e-02]\n",
      " [4.8500000e+02 3.4790000e+03 1.2232030e-01]\n",
      " [6.0000000e+02 4.0830000e+03 1.2809564e-01]\n",
      " [8.9100000e+02 7.3920000e+03 1.0755674e-01]\n",
      " [8.4000000e+01 2.4650000e+03 3.2941177e-02]\n",
      " [1.0440000e+03 3.4380000e+03 2.3287977e-01]\n",
      " [2.6000000e+01 1.6100000e+02 1.3829787e-01]\n",
      " [3.1400000e+02 1.3300000e+03 1.9088146e-01]\n",
      " [6.5000000e+01 5.8700000e+02 9.9540584e-02]\n",
      " [1.5100000e+02 4.5900000e+02 2.4713585e-01]\n",
      " [3.6000000e+01 5.1700000e+02 6.4981952e-02]\n",
      " [2.9700000e+02 1.4070000e+03 1.7419355e-01]\n",
      " [8.0000000e+00 2.8000000e+01 2.1621622e-01]\n",
      " [2.9000000e+01 5.2500000e+02 5.2252252e-02]\n",
      " [4.5000000e+01 3.7700000e+02 1.0638298e-01]\n",
      " [8.8000000e+01 4.6200000e+02 1.5970962e-01]\n",
      " [1.2500000e+02 8.6800000e+02 1.2575452e-01]], shape=(52, 3), dtype=float32)\n",
      "detailed_occupation_recode vocabulary ['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '5', '6', '7', '8', '9']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc5a22e0>\n",
      "### Adapting target encoding for: detailed_occupation_recode\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[9.06000000e+02 9.97780000e+04 8.99836142e-03]\n",
      " [1.33000000e+02 4.11000000e+02 2.44036704e-01]\n",
      " [3.78000000e+02 3.30500000e+03 1.02605864e-01]\n",
      " [4.20000000e+02 2.17000000e+02 6.58307195e-01]\n",
      " [4.57000000e+02 2.88300000e+03 1.36785388e-01]\n",
      " [6.70000000e+01 1.20400000e+03 5.26729561e-02]\n",
      " [1.21000000e+02 8.11000000e+02 1.29689172e-01]\n",
      " [1.73000000e+02 6.42000000e+02 2.12009802e-01]\n",
      " [6.04000000e+02 2.84100000e+03 1.75275683e-01]\n",
      " [4.81000000e+02 1.29000000e+03 2.71444708e-01]\n",
      " [2.97000000e+02 7.86000000e+02 2.73985237e-01]\n",
      " [1.38000000e+02 5.27500000e+03 2.54894719e-02]\n",
      " [2.82100000e+03 5.93500000e+03 3.22142273e-01]\n",
      " [4.00000000e+00 6.70000000e+01 5.55555560e-02]\n",
      " [8.10000000e+01 4.52000000e+02 1.51685387e-01]\n",
      " [2.70000000e+01 3.84000000e+02 6.55339807e-02]\n",
      " [5.80000000e+01 3.33400000e+03 1.70940179e-02]\n",
      " [4.30000000e+01 1.80400000e+03 2.32683979e-02]\n",
      " [4.70000000e+01 7.20000000e+02 6.11979179e-02]\n",
      " [1.90000000e+02 7.69700000e+03 2.40872204e-02]\n",
      " [2.00000000e+00 7.78000000e+02 2.56081950e-03]\n",
      " [2.59000000e+02 1.40200000e+03 1.55836344e-01]\n",
      " [2.80000000e+01 5.07700000e+03 5.48374467e-03]\n",
      " [6.39000000e+02 2.55600000e+03 1.99937418e-01]\n",
      " [2.70000000e+01 1.87000000e+03 1.42255006e-02]\n",
      " [2.80000000e+01 2.67100000e+03 1.03703700e-02]\n",
      " [3.70000000e+01 2.36100000e+03 1.54230930e-02]\n",
      " [3.54000000e+02 2.97100000e+03 1.06434152e-01]\n",
      " [2.98000000e+02 3.72700000e+03 7.40188807e-02]\n",
      " [3.03000000e+02 2.86500000e+03 9.56137553e-02]\n",
      " [1.49000000e+02 3.99600000e+03 3.59382555e-02]\n",
      " [8.60000000e+01 2.14800000e+03 3.84787470e-02]\n",
      " [1.65000000e+02 2.83800000e+03 5.49267642e-02]\n",
      " [9.40000000e+01 9.23000000e+02 9.23379138e-02]\n",
      " [6.79000000e+02 6.85000000e+02 4.97435898e-01]\n",
      " [1.90000000e+01 5.98000000e+02 3.07443365e-02]\n",
      " [2.70000000e+01 1.56500000e+03 1.69491526e-02]\n",
      " [3.30000000e+01 1.88500000e+03 1.71964560e-02]\n",
      " [1.16000000e+02 1.26600000e+03 8.38756338e-02]\n",
      " [2.40000000e+01 1.56800000e+03 1.50659131e-02]\n",
      " [2.00000000e+01 1.52000000e+02 1.15606934e-01]\n",
      " [8.00000000e+00 2.80000000e+01 2.16216221e-01]\n",
      " [3.17000000e+02 5.38000000e+02 3.70327115e-01]\n",
      " [1.54000000e+02 2.87000000e+02 3.48416299e-01]\n",
      " [5.00000000e+02 2.31000000e+02 6.83060110e-01]\n",
      " [3.71000000e+02 1.78000000e+03 1.72397763e-01]\n",
      " [1.99000000e+02 5.39000000e+02 2.69282818e-01]], shape=(47, 3), dtype=float32)\n",
      "education vocabulary [' 10th grade', ' 11th grade', ' 12th grade no diploma', ' 1st 2nd 3rd or 4th grade', ' 5th or 6th grade', ' 7th and 8th grade', ' 9th grade', ' Associates degree-academic program', ' Associates degree-occup /vocational', ' Bachelors degree(BA AB BS)', ' Children', ' Doctorate degree(PhD EdD)', ' High school graduate', ' Less than 1st grade', ' Masters degree(MA MS MEng MEd MSW MBA)', ' Prof school degree (MD DDS DVM LLB JD)', ' Some college but no degree']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc2309d0>\n",
      "### Adapting target encoding for: education\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[6.20000000e+01 7.49500000e+03 8.20322800e-03]\n",
      " [7.00000000e+01 6.80600000e+03 1.01788575e-02]\n",
      " [3.40000000e+01 2.09200000e+03 1.59849562e-02]\n",
      " [1.30000000e+01 1.78600000e+03 7.22222216e-03]\n",
      " [2.20000000e+01 3.25500000e+03 6.71140943e-03]\n",
      " [7.20000000e+01 7.93500000e+03 8.99100862e-03]\n",
      " [3.80000000e+01 6.19200000e+03 6.09853957e-03]\n",
      " [4.12000000e+02 3.95100000e+03 9.44088027e-02]\n",
      " [4.13000000e+02 4.94500000e+03 7.70666152e-02]\n",
      " [3.91500000e+03 1.59500000e+04 1.97070375e-01]\n",
      " [0.00000000e+00 4.74220000e+04 0.00000000e+00]\n",
      " [6.57000000e+02 6.06000000e+02 5.19778490e-01]\n",
      " [1.87900000e+03 4.65280000e+04 3.88158970e-02]\n",
      " [1.00000000e+00 8.18000000e+02 1.21951220e-03]\n",
      " [2.03800000e+03 4.50300000e+03 3.11525524e-01]\n",
      " [9.69000000e+02 8.24000000e+02 5.40133774e-01]\n",
      " [1.78700000e+03 2.60330000e+04 6.42320514e-02]], shape=(17, 3), dtype=float32)\n",
      "enroll_in_edu_inst_last_wk vocabulary [' College or university', ' High school', ' Not in universe']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc74f3a0>\n",
      "### Adapting target encoding for: enroll_in_edu_inst_last_wk\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[2.5000000e+01 5.6630000e+03 4.3944456e-03]\n",
      " [5.0000000e+00 6.8870000e+03 7.2537357e-04]\n",
      " [1.2352000e+04 1.7459100e+05 6.6073261e-02]], shape=(3, 3), dtype=float32)\n",
      "marital_stat vocabulary [' Divorced', ' Married-A F spouse present', ' Married-civilian spouse present', ' Married-spouse absent', ' Never married', ' Separated', ' Widowed']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc74f850>\n",
      "### Adapting target encoding for: marital_stat\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[1.0660000e+03 1.1644000e+04 8.3864368e-02]\n",
      " [1.5000000e+01 6.5000000e+02 2.2522522e-02]\n",
      " [9.6000000e+03 7.4622000e+04 1.1398312e-01]\n",
      " [9.6000000e+01 1.4220000e+03 6.3199475e-02]\n",
      " [1.1170000e+03 8.5368000e+04 1.2915385e-02]\n",
      " [1.5800000e+02 3.3020000e+03 4.5651548e-02]\n",
      " [3.3000000e+02 1.0133000e+04 3.1536698e-02]], shape=(7, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "major_industry_code vocabulary [' Agriculture', ' Armed Forces', ' Business and repair services', ' Communications', ' Construction', ' Education', ' Entertainment', ' Finance insurance and real estate', ' Forestry and fisheries', ' Hospital services', ' Manufacturing-durable goods', ' Manufacturing-nondurable goods', ' Medical except hospital', ' Mining', ' Not in universe or children', ' Other professional services', ' Personal services except private HH', ' Private household services', ' Public administration', ' Retail trade', ' Social services', ' Transportation', ' Utilities and sanitary services', ' Wholesale trade']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc0f1340>\n",
      "### Adapting target encoding for: major_industry_code\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[1.7800000e+02 2.8450000e+03 5.8862433e-02]\n",
      " [8.0000000e+00 2.8000000e+01 2.1621622e-01]\n",
      " [6.1900000e+02 5.0320000e+03 1.0951875e-01]\n",
      " [2.7000000e+02 9.1100000e+02 2.2842640e-01]\n",
      " [5.3300000e+02 5.4510000e+03 8.9055970e-02]\n",
      " [8.9100000e+02 7.3920000e+03 1.0755674e-01]\n",
      " [1.1300000e+02 1.5380000e+03 6.8401940e-02]\n",
      " [1.1190000e+03 5.0260000e+03 1.8206964e-01]\n",
      " [2.6000000e+01 1.6100000e+02 1.3829787e-01]\n",
      " [4.8500000e+02 3.4790000e+03 1.2232030e-01]\n",
      " [1.4940000e+03 7.5210000e+03 1.6570541e-01]\n",
      " [8.5600000e+02 6.0410000e+03 1.2409394e-01]\n",
      " [6.0000000e+02 4.0830000e+03 1.2809564e-01]\n",
      " [1.4600000e+02 4.1700000e+02 2.5886524e-01]\n",
      " [9.0600000e+02 9.9778000e+04 8.9983614e-03]\n",
      " [1.0440000e+03 3.4380000e+03 2.3287977e-01]\n",
      " [1.0500000e+02 2.8320000e+03 3.5738599e-02]\n",
      " [5.0000000e+00 9.4000000e+02 5.2854121e-03]\n",
      " [8.2700000e+02 3.7830000e+03 1.7935371e-01]\n",
      " [7.8900000e+02 1.6281000e+04 4.6218734e-02]\n",
      " [8.4000000e+01 2.4650000e+03 3.2941177e-02]\n",
      " [4.7600000e+02 3.7330000e+03 1.1306413e-01]\n",
      " [2.5600000e+02 9.2200000e+02 2.1713316e-01]\n",
      " [5.5200000e+02 3.0440000e+03 1.5346122e-01]], shape=(24, 3), dtype=float32)\n",
      "major_occupation_code vocabulary [' Adm support including clerical', ' Armed Forces', ' Executive admin and managerial', ' Farming forestry and fishing', ' Handlers equip cleaners etc ', ' Machine operators assmblrs & inspctrs', ' Not in universe', ' Other service', ' Precision production craft & repair', ' Private household services', ' Professional specialty', ' Protective services', ' Sales', ' Technicians and related support', ' Transportation and material moving']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc5732b0>\n",
      "### Adapting target encoding for: major_occupation_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[4.4600000e+02 1.4391000e+04 3.0057959e-02]\n",
      " [8.0000000e+00 2.8000000e+01 2.1621622e-01]\n",
      " [3.5930000e+03 8.9020000e+03 2.8753200e-01]\n",
      " [1.6000000e+02 2.9860000e+03 5.0842073e-02]\n",
      " [7.9000000e+01 4.0480000e+03 1.9137597e-02]\n",
      " [2.3500000e+02 6.1440000e+03 3.6833856e-02]\n",
      " [9.0600000e+02 9.9778000e+04 8.9983614e-03]\n",
      " [1.2000000e+02 1.1979000e+04 9.9173551e-03]\n",
      " [9.5500000e+02 9.5630000e+03 9.0788096e-02]\n",
      " [2.0000000e+00 7.7800000e+02 2.5608195e-03]\n",
      " [3.4750000e+03 1.0465000e+04 2.4926476e-01]\n",
      " [2.5900000e+02 1.4020000e+03 1.5583634e-01]\n",
      " [1.5240000e+03 1.0259000e+04 1.2932791e-01]\n",
      " [3.6100000e+02 2.6570000e+03 1.1957602e-01]\n",
      " [2.5900000e+02 3.7610000e+03 6.4411841e-02]], shape=(15, 3), dtype=float32)\n",
      "race vocabulary [' Amer Indian Aleut or Eskimo', ' Asian or Pacific Islander', ' Black', ' Other', ' White']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc59c280>\n",
      "### Adapting target encoding for: race\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[4.9000000e+01 2.2020000e+03 2.1758437e-02]\n",
      " [4.3000000e+02 5.4050000e+03 7.3680602e-02]\n",
      " [5.4000000e+02 1.9875000e+04 2.6449842e-02]\n",
      " [9.1000000e+01 3.5660000e+03 2.4876982e-02]\n",
      " [1.1272000e+04 1.5609300e+05 6.7349404e-02]], shape=(5, 3), dtype=float32)\n",
      "hispanic_origin vocabulary [' All other', ' Central or South American', ' Chicano', ' Cuban', ' Do not know', ' Mexican (Mexicano)', ' Mexican-American', ' NA', ' Other Spanish', ' Puerto Rican']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc433910>\n",
      "### Adapting target encoding for: hispanic_origin\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[1.1767000e+04 1.6014000e+05 6.8449400e-02]\n",
      " [8.0000000e+01 3.8150000e+03 2.0533880e-02]\n",
      " [6.0000000e+00 2.9800000e+02 1.9672131e-02]\n",
      " [6.1000000e+01 1.0650000e+03 5.4125998e-02]\n",
      " [8.0000000e+00 2.9800000e+02 2.6058631e-02]\n",
      " [8.2000000e+01 7.1520000e+03 1.1333794e-02]\n",
      " [1.7200000e+02 7.9070000e+03 2.1287128e-02]\n",
      " [5.7000000e+01 8.1700000e+02 6.5142855e-02]\n",
      " [8.1000000e+01 2.4040000e+03 3.2582462e-02]\n",
      " [6.8000000e+01 3.2450000e+03 2.0519011e-02]], shape=(10, 3), dtype=float32)\n",
      "sex vocabulary [' Female', ' Male']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc433b80>\n",
      "### Adapting target encoding for: sex\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[2.6630000e+03 1.0132100e+05 2.5609463e-02]\n",
      " [9.7190000e+03 8.5820000e+04 1.0172702e-01]], shape=(2, 3), dtype=float32)\n",
      "member_of_a_labor_union vocabulary [' No', ' Not in universe', ' Yes']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc1ae160>\n",
      "### Adapting target encoding for: member_of_a_labor_union\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[1.8220000e+03 1.4212000e+04 1.1362644e-01]\n",
      " [1.0148000e+04 1.7031100e+05 5.6234069e-02]\n",
      " [4.1200000e+02 2.6180000e+03 1.3592874e-01]], shape=(3, 3), dtype=float32)\n",
      "reason_for_unemployment vocabulary [' Job leaver', ' Job loser - on layoff', ' New entrant', ' Not in universe', ' Other job loser', ' Re-entrant']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc310a30>\n",
      "### Adapting target encoding for: reason_for_unemployment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[2.4000000e+01 5.7400000e+02 4.0066779e-02]\n",
      " [2.2000000e+01 9.5400000e+02 2.2517912e-02]\n",
      " [2.0000000e+00 4.3700000e+02 4.5454544e-03]\n",
      " [1.2212000e+04 1.8124100e+05 6.3126117e-02]\n",
      " [9.9000000e+01 1.9390000e+03 4.8553213e-02]\n",
      " [2.3000000e+01 1.9960000e+03 1.1386138e-02]], shape=(6, 3), dtype=float32)\n",
      "full_or_part_time_employment_stat vocabulary [' Children or Armed Forces', ' Full-time schedules', ' Not in labor force', ' PT for econ reasons usually FT', ' PT for econ reasons usually PT', ' PT for non-econ reasons usually FT', ' Unemployed full-time', ' Unemployed part- time']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc5e7df0>\n",
      "### Adapting target encoding for: full_or_part_time_employment_stat\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[5.8740000e+03 1.1789500e+05 4.7458995e-02]\n",
      " [5.3660000e+03 3.5370000e+04 1.3172300e-01]\n",
      " [4.6200000e+02 2.6346000e+04 1.7233018e-02]\n",
      " [3.1000000e+01 4.9400000e+02 5.8935363e-02]\n",
      " [1.5500000e+02 1.0540000e+03 1.2809917e-01]\n",
      " [3.9300000e+02 2.9290000e+03 1.1826663e-01]\n",
      " [8.3000000e+01 2.2280000e+03 3.5899654e-02]\n",
      " [1.8000000e+01 8.2500000e+02 2.1327015e-02]], shape=(8, 3), dtype=float32)\n",
      "tax_filer_stat vocabulary [' Head of household', ' Joint both 65+', ' Joint both under 65', ' Joint one under 65 & one 65+', ' Nonfiler', ' Single']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc2d0100>\n",
      "### Adapting target encoding for: tax_filer_stat\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[4.4800000e+02 6.9780000e+03 6.0320452e-02]\n",
      " [4.5000000e+02 7.8820000e+03 5.4002158e-02]\n",
      " [8.8530000e+03 5.8530000e+04 1.3138133e-01]\n",
      " [3.0100000e+02 3.5660000e+03 7.7817991e-02]\n",
      " [3.5000000e+01 7.5059000e+04 4.6607631e-04]\n",
      " [2.2950000e+03 3.5126000e+04 6.1327562e-02]], shape=(6, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_of_previous_residence vocabulary [' Abroad', ' Midwest', ' Northeast', ' Not in universe', ' South', ' West']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc229eb0>\n",
      "### Adapting target encoding for: region_of_previous_residence\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[1.8000000e+01 5.1200000e+02 3.3898305e-02]\n",
      " [1.0900000e+02 3.4660000e+03 3.0480985e-02]\n",
      " [1.4700000e+02 2.5580000e+03 5.4323725e-02]\n",
      " [1.1764000e+04 1.7198600e+05 6.4021423e-02]\n",
      " [1.8400000e+02 4.7050000e+03 3.7627812e-02]\n",
      " [1.6000000e+02 3.9140000e+03 3.9263804e-02]], shape=(6, 3), dtype=float32)\n",
      "state_of_previous_residence vocabulary [' ?', ' Abroad', ' Alabama', ' Alaska', ' Arizona', ' Arkansas', ' California', ' Colorado', ' Connecticut', ' Delaware', ' District of Columbia', ' Florida', ' Georgia', ' Idaho', ' Illinois', ' Indiana', ' Iowa', ' Kansas', ' Kentucky', ' Louisiana', ' Maine', ' Maryland', ' Massachusetts', ' Michigan', ' Minnesota', ' Mississippi', ' Missouri', ' Montana', ' Nebraska', ' Nevada', ' New Hampshire', ' New Jersey', ' New Mexico', ' New York', ' North Carolina', ' North Dakota', ' Not in universe', ' Ohio', ' Oklahoma', ' Oregon', ' Pennsylvania', ' South Carolina', ' South Dakota', ' Tennessee', ' Texas', ' Utah', ' Vermont', ' Virginia', ' West Virginia', ' Wisconsin', ' Wyoming']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc63ffd0>\n",
      "### Adapting target encoding for: state_of_previous_residence\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[4.5000000e+01 6.6300000e+02 6.3469678e-02]\n",
      " [2.3000000e+01 6.4800000e+02 3.4226190e-02]\n",
      " [6.0000000e+00 2.1000000e+02 2.7649770e-02]\n",
      " [2.3000000e+01 2.6700000e+02 7.9037800e-02]\n",
      " [4.0000000e+00 2.3900000e+02 1.6393442e-02]\n",
      " [6.0000000e+00 1.9900000e+02 2.9126214e-02]\n",
      " [6.7000000e+01 1.6470000e+03 3.9067056e-02]\n",
      " [1.1000000e+01 2.2800000e+02 4.5833334e-02]\n",
      " [1.2000000e+01 1.0500000e+02 1.0169491e-01]\n",
      " [3.0000000e+00 7.0000000e+01 4.0540539e-02]\n",
      " [1.1000000e+01 1.0500000e+02 9.4017096e-02]\n",
      " [3.0000000e+01 8.1900000e+02 3.5294119e-02]\n",
      " [5.0000000e+00 2.2200000e+02 2.1929825e-02]\n",
      " [2.0000000e+00 2.9000000e+01 6.2500000e-02]\n",
      " [6.0000000e+00 1.7400000e+02 3.3149172e-02]\n",
      " [1.6000000e+01 5.1700000e+02 2.9962547e-02]\n",
      " [4.0000000e+00 1.8500000e+02 2.1052632e-02]\n",
      " [4.0000000e+00 1.4500000e+02 2.6666667e-02]\n",
      " [1.0000000e+01 2.3400000e+02 4.0816326e-02]\n",
      " [3.0000000e+00 1.8900000e+02 1.5544041e-02]\n",
      " [1.0000000e+01 1.5700000e+02 5.9523810e-02]\n",
      " [3.0000000e+00 1.3300000e+02 2.1897810e-02]\n",
      " [1.1000000e+01 1.4000000e+02 7.2368421e-02]\n",
      " [1.9000000e+01 4.2200000e+02 4.2986427e-02]\n",
      " [2.0000000e+01 5.5600000e+02 3.4662046e-02]\n",
      " [5.0000000e+00 1.9900000e+02 2.4390243e-02]\n",
      " [5.0000000e+00 1.7000000e+02 2.8409092e-02]\n",
      " [7.0000000e+00 2.1900000e+02 3.0837005e-02]\n",
      " [3.0000000e+00 1.7500000e+02 1.6759777e-02]\n",
      " [4.0000000e+00 1.7000000e+02 2.2857143e-02]\n",
      " [9.0000000e+00 2.3300000e+02 3.7037037e-02]\n",
      " [7.0000000e+00 6.8000000e+01 9.2105262e-02]\n",
      " [3.0000000e+01 4.3300000e+02 6.4655170e-02]\n",
      " [7.0000000e+00 1.8800000e+02 3.5714287e-02]\n",
      " [4.3000000e+01 7.6900000e+02 5.2890528e-02]\n",
      " [1.8000000e+01 4.8100000e+02 3.5999998e-02]\n",
      " [1.1764000e+04 1.7198600e+05 6.4021423e-02]\n",
      " [5.0000000e+00 2.0600000e+02 2.3584906e-02]\n",
      " [2.0000000e+01 6.0600000e+02 3.1897925e-02]\n",
      " [8.0000000e+00 2.2800000e+02 3.3755273e-02]\n",
      " [6.0000000e+00 1.9300000e+02 2.9999999e-02]\n",
      " [4.0000000e+00 9.1000000e+01 4.1666668e-02]\n",
      " [5.0000000e+00 1.3300000e+02 3.5971224e-02]\n",
      " [4.0000000e+00 1.9800000e+02 1.9704433e-02]\n",
      " [8.0000000e+00 2.0100000e+02 3.8095240e-02]\n",
      " [3.1000000e+01 1.0320000e+03 2.9135339e-02]\n",
      " [5.0000000e+00 1.8600000e+02 2.6041666e-02]\n",
      " [3.0000000e+00 1.2300000e+02 2.3622047e-02]\n",
      " [1.2000000e+01 2.1900000e+02 5.1724140e-02]\n",
      " [5.0000000e+00 1.0000000e+02 4.7169812e-02]\n",
      " [1.0000000e+01 2.3100000e+02 4.1322313e-02]], shape=(51, 3), dtype=float32)\n",
      "detailed_household_and_family_stat vocabulary [' Child 18+ ever marr Not in a subfamily', ' Child 18+ ever marr RP of subfamily', ' Child 18+ never marr Not in a subfamily', ' Child 18+ never marr RP of subfamily', ' Child 18+ spouse of subfamily RP', ' Child <18 ever marr RP of subfamily', ' Child <18 ever marr not in subfamily', ' Child <18 never marr RP of subfamily', ' Child <18 never marr not in subfamily', ' Child <18 spouse of subfamily RP', ' Child under 18 of RP of unrel subfamily', ' Grandchild 18+ ever marr RP of subfamily', ' Grandchild 18+ ever marr not in subfamily', ' Grandchild 18+ never marr RP of subfamily', ' Grandchild 18+ never marr not in subfamily', ' Grandchild 18+ spouse of subfamily RP', ' Grandchild <18 ever marr not in subfamily', ' Grandchild <18 never marr RP of subfamily', ' Grandchild <18 never marr child of subfamily RP', ' Grandchild <18 never marr not in subfamily', ' Householder', ' In group quarters', ' Nonfamily householder', ' Other Rel 18+ ever marr RP of subfamily', ' Other Rel 18+ ever marr not in subfamily', ' Other Rel 18+ never marr RP of subfamily', ' Other Rel 18+ never marr not in subfamily', ' Other Rel 18+ spouse of subfamily RP', ' Other Rel <18 ever marr RP of subfamily', ' Other Rel <18 ever marr not in subfamily', ' Other Rel <18 never marr child of subfamily RP', ' Other Rel <18 never marr not in subfamily', ' Other Rel <18 never married RP of subfamily', ' Other Rel <18 spouse of subfamily RP', ' RP of unrelated subfamily', ' Secondary individual', ' Spouse of RP of unrelated subfamily', ' Spouse of householder']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc7d1ac0>\n",
      "### Adapting target encoding for: detailed_household_and_family_stat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[2.3000000e+01 9.9000000e+02 2.2682445e-02]\n",
      " [1.2000000e+01 6.5900000e+02 1.7857144e-02]\n",
      " [8.7000000e+01 1.1943000e+04 7.2313193e-03]\n",
      " [2.0000000e+00 5.8700000e+02 3.3898305e-03]\n",
      " [2.0000000e+00 1.2400000e+02 1.5748031e-02]\n",
      " [0.0000000e+00 9.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 3.6000000e+01 0.0000000e+00]\n",
      " [0.0000000e+00 8.0000000e+01 0.0000000e+00]\n",
      " [2.0000000e+00 5.0324000e+04 3.9740098e-05]\n",
      " [0.0000000e+00 2.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 7.3200000e+02 0.0000000e+00]\n",
      " [0.0000000e+00 9.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 3.3000000e+01 2.8571429e-02]\n",
      " [0.0000000e+00 6.0000000e+00 0.0000000e+00]\n",
      " [2.0000000e+00 3.7300000e+02 5.3191488e-03]\n",
      " [0.0000000e+00 1.0000000e+01 0.0000000e+00]\n",
      " [0.0000000e+00 2.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.8680000e+03 0.0000000e+00]\n",
      " [0.0000000e+00 1.0660000e+03 0.0000000e+00]\n",
      " [7.8500000e+03 4.5398000e+04 1.4742061e-01]\n",
      " [2.0000000e+00 1.9400000e+02 1.0152284e-02]\n",
      " [1.8000000e+03 2.0413000e+04 8.1029981e-02]\n",
      " [1.9000000e+01 6.3700000e+02 2.8919330e-02]\n",
      " [1.8000000e+01 1.9380000e+03 9.1977520e-03]\n",
      " [0.0000000e+00 9.4000000e+01 0.0000000e+00]\n",
      " [2.2000000e+01 1.7060000e+03 1.2724118e-02]\n",
      " [2.4000000e+01 6.1400000e+02 3.7558686e-02]\n",
      " [0.0000000e+00 6.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 6.5600000e+02 0.0000000e+00]\n",
      " [0.0000000e+00 5.8400000e+02 0.0000000e+00]\n",
      " [0.0000000e+00 4.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 3.0000000e+00 0.0000000e+00]\n",
      " [9.0000000e+00 6.7600000e+02 1.3119534e-02]\n",
      " [2.2000000e+02 5.9020000e+03 3.5930101e-02]\n",
      " [5.0000000e+00 4.7000000e+01 9.4339624e-02]\n",
      " [2.2820000e+03 3.9413000e+04 5.4729469e-02]], shape=(38, 3), dtype=float32)\n",
      "detailed_household_summary_in_household vocabulary [' Child 18 or older', ' Child under 18 ever married', ' Child under 18 never married', ' Group Quarters- Secondary individual', ' Householder', ' Nonrelative of householder', ' Other relative of householder', ' Spouse of householder']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc21cee0>\n",
      "### Adapting target encoding for: detailed_household_summary_in_household\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[1.2600000e+02 1.4304000e+04 8.7312041e-03]\n",
      " [0.0000000e+00 4.7000000e+01 0.0000000e+00]\n",
      " [2.0000000e+00 5.0424000e+04 3.9661292e-05]\n",
      " [1.0000000e+00 1.3100000e+02 7.5187972e-03]\n",
      " [9.6510000e+03 6.5824000e+04 1.2786846e-01]\n",
      " [2.3400000e+02 7.3670000e+03 3.0781373e-02]\n",
      " [8.6000000e+01 9.6170000e+03 8.8623250e-03]\n",
      " [2.2820000e+03 3.9427000e+04 5.4711100e-02]], shape=(8, 3), dtype=float32)\n",
      "migration_code-change_in_msa vocabulary [' ?', ' Abroad to MSA', ' Abroad to nonMSA', ' MSA to MSA', ' MSA to nonMSA', ' NonMSA to MSA', ' NonMSA to nonMSA', ' Nonmover', ' Not identifiable', ' Not in universe']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc6a4b20>\n",
      "### Adapting target encoding for: migration_code-change_in_msa\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[6.5430000e+03 9.3153000e+04 6.5628856e-02]\n",
      " [1.8000000e+01 4.3500000e+02 3.9647575e-02]\n",
      " [0.0000000e+00 7.3000000e+01 0.0000000e+00]\n",
      " [4.8200000e+02 1.0119000e+04 4.5463119e-02]\n",
      " [2.4000000e+01 7.6600000e+02 3.0341340e-02]\n",
      " [2.7000000e+01 5.8800000e+02 4.3831170e-02]\n",
      " [5.0000000e+01 2.7610000e+03 1.7780939e-02]\n",
      " [5.2210000e+03 7.7317000e+04 6.3254945e-02]\n",
      " [1.7000000e+01 4.1300000e+02 3.9443154e-02]\n",
      " [0.0000000e+00 1.5160000e+03 0.0000000e+00]], shape=(10, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "migration_code-change_in_reg vocabulary [' ?', ' Abroad', ' Different county same state', ' Different division same region', ' Different region', ' Different state same division', ' Nonmover', ' Not in universe', ' Same county']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc71f700>\n",
      "### Adapting target encoding for: migration_code-change_in_reg\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[6.5430000e+03 9.3153000e+04 6.5628856e-02]\n",
      " [1.8000000e+01 5.1200000e+02 3.3898305e-02]\n",
      " [1.2700000e+02 2.6700000e+03 4.5389563e-02]\n",
      " [2.5000000e+01 4.4000000e+02 5.3648070e-02]\n",
      " [7.5000000e+01 1.1030000e+03 6.3613228e-02]\n",
      " [4.5000000e+01 9.4600000e+02 4.5362905e-02]\n",
      " [5.2210000e+03 7.7317000e+04 6.3254945e-02]\n",
      " [0.0000000e+00 1.5160000e+03 0.0000000e+00]\n",
      " [3.2800000e+02 9.4840000e+03 3.3425048e-02]], shape=(9, 3), dtype=float32)\n",
      "migration_code-move_within_reg vocabulary [' ?', ' Abroad', ' Different county same state', ' Different state in Midwest', ' Different state in Northeast', ' Different state in South', ' Different state in West', ' Nonmover', ' Not in universe', ' Same county']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc403a60>\n",
      "### Adapting target encoding for: migration_code-move_within_reg\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[6.5430000e+03 9.3153000e+04 6.5628856e-02]\n",
      " [1.8000000e+01 5.1200000e+02 3.3898305e-02]\n",
      " [1.2700000e+02 2.6700000e+03 4.5389563e-02]\n",
      " [2.5000000e+01 5.2600000e+02 4.5289855e-02]\n",
      " [2.7000000e+01 4.0400000e+02 6.2500000e-02]\n",
      " [6.1000000e+01 9.1200000e+02 6.2628336e-02]\n",
      " [3.2000000e+01 6.4700000e+02 4.7058824e-02]\n",
      " [5.2210000e+03 7.7317000e+04 6.3254945e-02]\n",
      " [0.0000000e+00 1.5160000e+03 0.0000000e+00]\n",
      " [3.2800000e+02 9.4840000e+03 3.3425048e-02]], shape=(10, 3), dtype=float32)\n",
      "live_in_this_house_1_year_ago vocabulary [' No', ' Not in universe under 1 year old', ' Yes']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc59fe50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Adapting target encoding for: live_in_this_house_1_year_ago\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[6.1800000e+02 1.5155000e+04 3.9178394e-02]\n",
      " [6.5430000e+03 9.4669000e+04 6.4645849e-02]\n",
      " [5.2210000e+03 7.7317000e+04 6.3254945e-02]], shape=(3, 3), dtype=float32)\n",
      "migration_prev_res_in_sunbelt vocabulary [' ?', ' No', ' Not in universe', ' Yes']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc245340>\n",
      "### Adapting target encoding for: migration_prev_res_in_sunbelt\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[6.5430000e+03 9.3153000e+04 6.5628856e-02]\n",
      " [4.2400000e+02 9.5630000e+03 4.2450942e-02]\n",
      " [5.2210000e+03 7.8833000e+04 6.2114093e-02]\n",
      " [1.9400000e+02 5.5920000e+03 3.3523414e-02]], shape=(4, 3), dtype=float32)\n",
      "family_members_under_18 vocabulary [' Both parents present', ' Father only present', ' Mother only present', ' Neither parent present', ' Not in universe']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc451a30>\n",
      "### Adapting target encoding for: family_members_under_18\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[2.0000000e+00 3.8981000e+04 5.1303097e-05]\n",
      " [0.0000000e+00 1.8830000e+03 0.0000000e+00]\n",
      " [0.0000000e+00 1.2772000e+04 0.0000000e+00]\n",
      " [0.0000000e+00 1.6530000e+03 0.0000000e+00]\n",
      " [1.2380000e+04 1.3185200e+05 8.5833341e-02]], shape=(5, 3), dtype=float32)\n",
      "country_of_birth_father vocabulary [' ?', ' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong Kong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-U S (Guam USVI etc)', ' Panama', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South Korea', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc21ba60>\n",
      "### Adapting target encoding for: country_of_birth_father\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[5.49000000e+02 6.16400000e+03 8.17694366e-02]\n",
      " [5.00000000e+00 1.91000000e+02 2.53807101e-02]\n",
      " [1.30000000e+02 1.25000000e+03 9.41346884e-02]\n",
      " [7.80000000e+01 7.78000000e+02 9.10151675e-02]\n",
      " [1.40000000e+01 6.00000000e+02 2.27642283e-02]\n",
      " [5.90000000e+01 1.06600000e+03 5.23978695e-02]\n",
      " [1.40000000e+01 1.27600000e+03 1.08443070e-02]\n",
      " [1.10000000e+01 3.68000000e+02 2.89473683e-02]\n",
      " [7.00000000e+00 9.75000000e+02 7.12105818e-03]\n",
      " [7.90000000e+01 7.14000000e+02 9.94962230e-02]\n",
      " [1.30000000e+01 1.78000000e+02 6.77083358e-02]\n",
      " [1.10000000e+02 1.24600000e+03 8.10611621e-02]\n",
      " [3.90000000e+01 3.05000000e+02 1.13043480e-01]\n",
      " [2.00000000e+00 4.43000000e+02 4.48430516e-03]\n",
      " [9.00000000e+00 3.42000000e+02 2.55681816e-02]\n",
      " [7.00000000e+00 4.40000000e+01 1.34615391e-01]\n",
      " [1.00000000e+00 1.93000000e+02 5.12820529e-03]\n",
      " [5.00000000e+00 1.01000000e+02 4.67289723e-02]\n",
      " [3.40000000e+01 2.72000000e+02 1.10749185e-01]\n",
      " [7.90000000e+01 5.01000000e+02 1.35972455e-01]\n",
      " [3.00000000e+01 2.03000000e+02 1.28205135e-01]\n",
      " [6.50000000e+01 4.43000000e+02 1.27701372e-01]\n",
      " [1.44000000e+02 2.06800000e+03 6.50700405e-02]\n",
      " [2.20000000e+01 4.41000000e+02 4.74137925e-02]\n",
      " [4.30000000e+01 3.49000000e+02 1.09414756e-01]\n",
      " [2.00000000e+00 1.52000000e+02 1.29032256e-02]\n",
      " [1.24000000e+02 9.88400000e+03 1.23888496e-02]\n",
      " [8.00000000e+00 3.07000000e+02 2.53164563e-02]\n",
      " [8.00000000e+00 1.51000000e+02 5.00000007e-02]\n",
      " [0.00000000e+00 2.50000000e+01 0.00000000e+00]\n",
      " [9.00000000e+00 3.26000000e+02 2.67857146e-02]\n",
      " [8.40000000e+01 1.07000000e+03 7.27272704e-02]\n",
      " [1.02000000e+02 1.11000000e+03 8.40890333e-02]\n",
      " [2.00000000e+01 3.68000000e+02 5.14138825e-02]\n",
      " [6.60000000e+01 2.61400000e+03 2.46176794e-02]\n",
      " [2.00000000e+01 2.27000000e+02 8.06451589e-02]\n",
      " [3.20000000e+01 4.98000000e+02 6.02636524e-02]\n",
      " [2.00000000e+01 1.79000000e+02 1.00000001e-01]\n",
      " [8.00000000e+00 9.90000000e+01 7.40740746e-02]\n",
      " [2.00000000e+00 1.11000000e+02 1.75438598e-02]\n",
      " [1.03020000e+04 1.48861000e+05 6.47256896e-02]\n",
      " [1.10000000e+01 4.46000000e+02 2.40174681e-02]\n",
      " [1.50000000e+01 2.02000000e+02 6.88073412e-02]], shape=(43, 3), dtype=float32)\n",
      "country_of_birth_mother vocabulary [' ?', ' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong Kong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-U S (Guam USVI etc)', ' Panama', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South Korea', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc48f7c0>\n",
      "### Adapting target encoding for: country_of_birth_mother\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[4.69000000e+02 5.65000000e+03 7.66339898e-02]\n",
      " [6.00000000e+00 1.51000000e+02 3.79746817e-02]\n",
      " [1.36000000e+02 1.31500000e+03 9.36639085e-02]\n",
      " [7.00000000e+01 6.90000000e+02 9.19842348e-02]\n",
      " [1.20000000e+01 6.00000000e+02 1.95758566e-02]\n",
      " [6.20000000e+01 1.04600000e+03 5.59062213e-02]\n",
      " [1.10000000e+01 1.09200000e+03 9.96376853e-03]\n",
      " [1.20000000e+01 3.63000000e+02 3.19148935e-02]\n",
      " [2.00000000e+01 1.08800000e+03 1.80342644e-02]\n",
      " [9.90000000e+01 8.04000000e+02 1.09513275e-01]\n",
      " [2.50000000e+01 1.87000000e+02 1.17370889e-01]\n",
      " [1.21000000e+02 1.26100000e+03 8.74909610e-02]\n",
      " [2.20000000e+01 2.39000000e+02 8.39694664e-02]\n",
      " [3.00000000e+00 4.41000000e+02 6.74157310e-03]\n",
      " [8.00000000e+00 3.45000000e+02 2.25988701e-02]\n",
      " [7.00000000e+00 4.20000000e+01 1.40000001e-01]\n",
      " [2.00000000e+00 2.16000000e+02 9.13241971e-03]\n",
      " [7.00000000e+00 1.00000000e+02 6.48148134e-02]\n",
      " [3.30000000e+01 2.64000000e+02 1.10738255e-01]\n",
      " [8.10000000e+01 5.00000000e+02 1.39175251e-01]\n",
      " [2.70000000e+01 1.71000000e+02 1.35678396e-01]\n",
      " [7.30000000e+01 5.26000000e+02 1.21666670e-01]\n",
      " [1.03000000e+02 1.74100000e+03 5.58265597e-02]\n",
      " [2.10000000e+01 4.32000000e+02 4.62555066e-02]\n",
      " [5.30000000e+01 4.16000000e+02 1.12765960e-01]\n",
      " [2.00000000e+00 1.53000000e+02 1.28205130e-02]\n",
      " [1.36000000e+02 9.64500000e+03 1.39030870e-02]\n",
      " [6.00000000e+00 2.95000000e+02 1.98675506e-02]\n",
      " [2.00000000e+00 1.55000000e+02 1.26582282e-02]\n",
      " [0.00000000e+00 3.20000000e+01 0.00000000e+00]\n",
      " [9.00000000e+00 3.46000000e+02 2.52808984e-02]\n",
      " [7.90000000e+01 1.15200000e+03 6.41233772e-02]\n",
      " [9.60000000e+01 1.01400000e+03 8.64086375e-02]\n",
      " [1.60000000e+01 3.26000000e+02 4.66472320e-02]\n",
      " [5.30000000e+01 2.42000000e+03 2.14227978e-02]\n",
      " [2.70000000e+01 2.14000000e+02 1.11570247e-01]\n",
      " [3.50000000e+01 5.74000000e+02 5.73770478e-02]\n",
      " [2.00000000e+01 2.02000000e+02 8.96860957e-02]\n",
      " [7.00000000e+00 1.16000000e+02 5.64516112e-02]\n",
      " [2.00000000e+00 9.70000000e+01 1.99999996e-02]\n",
      " [1.03880000e+04 1.50091000e+05 6.47308081e-02]\n",
      " [1.10000000e+01 4.62000000e+02 2.32067518e-02]\n",
      " [1.00000000e+01 1.67000000e+02 5.61797768e-02]], shape=(43, 3), dtype=float32)\n",
      "country_of_birth_self vocabulary [' ?', ' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong Kong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-U S (Guam USVI etc)', ' Panama', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South Korea', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc0af400>\n",
      "### Adapting target encoding for: country_of_birth_self\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[2.9700000e+02 3.0960000e+03 8.7507367e-02]\n",
      " [1.0000000e+00 9.4000000e+01 1.0416667e-02]\n",
      " [6.9000000e+01 6.3100000e+02 9.8430812e-02]\n",
      " [3.5000000e+01 4.4300000e+02 7.3068894e-02]\n",
      " [9.0000000e+00 4.2500000e+02 2.0689655e-02]\n",
      " [6.0000000e+01 7.7700000e+02 7.1599044e-02]\n",
      " [1.1000000e+01 6.7900000e+02 1.5918959e-02]\n",
      " [9.0000000e+00 2.4900000e+02 3.4749035e-02]\n",
      " [1.3000000e+01 6.7600000e+02 1.8840579e-02]\n",
      " [5.8000000e+01 3.9900000e+02 1.2663755e-01]\n",
      " [1.5000000e+01 1.0600000e+02 1.2295082e-01]\n",
      " [7.2000000e+01 7.7900000e+02 8.4507041e-02]\n",
      " [1.5000000e+01 1.3200000e+02 1.0135135e-01]\n",
      " [3.0000000e+00 3.4100000e+02 8.6956518e-03]\n",
      " [8.0000000e+00 2.2000000e+02 3.4934498e-02]\n",
      " [5.0000000e+00 1.8000000e+01 2.0833333e-01]\n",
      " [2.0000000e+00 1.4200000e+02 1.3793103e-02]\n",
      " [1.0000000e+01 9.0000000e+01 9.9009901e-02]\n",
      " [8.0000000e+00 7.1000000e+01 1.0000000e-01]\n",
      " [7.1000000e+01 3.3700000e+02 1.7359413e-01]\n",
      " [2.8000000e+01 1.2900000e+02 1.7721519e-01]\n",
      " [1.4000000e+01 1.2100000e+02 1.0294118e-01]\n",
      " [3.2000000e+01 3.8700000e+02 7.6190479e-02]\n",
      " [1.8000000e+01 3.0200000e+02 5.6074765e-02]\n",
      " [4.0000000e+01 2.9900000e+02 1.1764706e-01]\n",
      " [1.0000000e+00 1.0400000e+02 9.4339624e-03]\n",
      " [7.5000000e+01 5.6920000e+03 1.3002774e-02]\n",
      " [2.0000000e+00 2.1600000e+02 9.1324197e-03]\n",
      " [3.0000000e+00 1.1600000e+02 2.5000000e-02]\n",
      " [0.0000000e+00 2.8000000e+01 0.0000000e+00]\n",
      " [9.0000000e+00 2.5900000e+02 3.3457249e-02]\n",
      " [7.8000000e+01 7.6700000e+02 9.2198581e-02]\n",
      " [2.3000000e+01 3.5800000e+02 6.0209423e-02]\n",
      " [9.0000000e+00 1.6500000e+02 5.1428571e-02]\n",
      " [3.0000000e+01 1.3700000e+03 2.1413276e-02]\n",
      " [1.3000000e+01 6.2000000e+01 1.7105263e-01]\n",
      " [2.9000000e+01 4.4200000e+02 6.1440676e-02]\n",
      " [3.1000000e+01 1.7000000e+02 1.5346535e-01]\n",
      " [9.0000000e+00 1.0400000e+02 7.8947365e-02]\n",
      " [1.0000000e+00 6.5000000e+01 1.4925373e-02]\n",
      " [1.1149000e+04 1.6584000e+05 6.2992260e-02]\n",
      " [1.1000000e+01 3.8000000e+02 2.8061224e-02]\n",
      " [6.0000000e+00 6.0000000e+01 8.9552239e-02]], shape=(43, 3), dtype=float32)\n",
      "citizenship vocabulary [' Foreign born- Not a citizen of U S ', ' Foreign born- U S citizen by naturalization', ' Native- Born abroad of American Parent(s)', ' Native- Born in Puerto Rico or U S Outlying', ' Native- Born in the United States']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc15b670>\n",
      "### Adapting target encoding for: citizenship\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[4.9200000e+02 1.2909000e+04 3.6710940e-02]\n",
      " [5.8000000e+02 5.2750000e+03 9.9043719e-02]\n",
      " [1.2800000e+02 1.6280000e+03 7.2851449e-02]\n",
      " [3.3000000e+01 1.4860000e+03 2.1710526e-02]\n",
      " [1.1149000e+04 1.6584300e+05 6.2991194e-02]], shape=(5, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "own_business_or_self_employed vocabulary ['0', '1', '2']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc15b520>\n",
      "### Adapting target encoding for: own_business_or_self_employed\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[1.0452000e+04 1.7022000e+05 5.7850372e-02]\n",
      " [6.0900000e+02 2.0890000e+03 2.2563912e-01]\n",
      " [1.3210000e+03 1.4832000e+04 8.1775412e-02]], shape=(3, 3), dtype=float32)\n",
      "fill_inc_questionnaire_for_veteran's_admin vocabulary [' No', ' Not in universe', ' Yes']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc48f6a0>\n",
      "### Adapting target encoding for: fill_inc_questionnaire_for_veteran's_admin\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[2.1500000e+02 1.3780000e+03 1.3488080e-01]\n",
      " [1.2151000e+04 1.8538800e+05 6.1511591e-02]\n",
      " [1.6000000e+01 3.7500000e+02 4.0816326e-02]], shape=(3, 3), dtype=float32)\n",
      "veterans_benefits vocabulary ['0', '1', '2']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2ecc4fafa0>\n",
      "### Adapting target encoding for: veterans_benefits\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[0.00000000e+00 4.74090000e+04 0.00000000e+00]\n",
      " [2.31000000e+02 1.75300000e+03 1.16372794e-01]\n",
      " [1.21510000e+04 1.37979000e+05 8.09359848e-02]], shape=(3, 3), dtype=float32)\n",
      "year vocabulary ['94', '95']\n",
      "lookup <keras.layers.preprocessing.string_lookup.StringLookup object at 0x7f2edc2b9160>\n",
      "### Adapting target encoding for: year\n",
      "** target_encoding_statics **\n",
      " tf.Tensor(\n",
      "[[5.8390000e+03 9.3988000e+04 5.8490604e-02]\n",
      " [6.5430000e+03 9.3153000e+04 6.5628856e-02]], shape=(2, 3), dtype=float32)\n",
      "Use /tmp/tmpcse795sf as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:06.694637. Found 199523 examples.\n",
      "Training model...\n",
      "Model trained in 0:02:59.516634\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO kernel.cc:1176] Loading model from path /tmp/tmpcse795sf/model/ with prefix d6785a542e5b49ad\n",
      "[INFO abstract_model.cc:1248] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO kernel.cc:1022] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 95.81%\n"
     ]
    }
   ],
   "source": [
    "gbt_model = create_gbt_with_preprocessor(create_target_encoder())\n",
    "run_experiment(gbt_model, train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf5c70",
   "metadata": {},
   "source": [
    "# Experiment 3: Decision Forests with trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec558cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Categorical feature 를 임베딩\n",
    "feature(str) --> value_index --> embedding \n",
    "'''\n",
    "\n",
    "def create_embedding_encoder(size=None, hidden_layers=1):\n",
    "    inputs = create_model_inputs()\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            # Get the vocabulary of the categorical feature.\n",
    "            vocabulary = sorted(\n",
    "                [str(value) for value in list(train_data[feature_name].unique())]\n",
    "            )\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            lookup = layers.StringLookup(\n",
    "                vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
    "            )\n",
    "            # Convert the string input values into integer indices.\n",
    "            value_index = lookup(inputs[feature_name])\n",
    "            # Create an embedding layer with the specified dimensions\n",
    "            vocabulary_size = len(vocabulary)\n",
    "            embedding_size = int(math.sqrt(vocabulary_size))\n",
    "            feature_encoder = layers.Embedding(\n",
    "                input_dim=len(vocabulary), output_dim=embedding_size\n",
    "            )\n",
    "            # Convert the index values to embedding representations.\n",
    "            encoded_feature = feature_encoder(value_index)\n",
    "        else:\n",
    "            # Expand the dimensions of the numerical input feature and use it as-is.\n",
    "            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "        # Add the encoded feature to the list.\n",
    "        encoded_features.append(encoded_feature)\n",
    "    # Concatenate all the encoded features.\n",
    "    encoded_features = layers.concatenate(encoded_features, axis=1)\n",
    "    for _ in range(hidden_layers):\n",
    "        # Apply dropout.\n",
    "        encoded_features = layers.Dropout(rate=0.25)(encoded_features)\n",
    "        # Perform non-linearity projection.\n",
    "        encoded_features = layers.Dense(\n",
    "            units=size if size else encoded_features.shape[-1], activation=\"gelu\"\n",
    "        )(encoded_features)\n",
    "    # Create and return a Keras model with encoded features as outputs.\n",
    "    return keras.Model(inputs=inputs, outputs=encoded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5dfd006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 8s 21ms/step - loss: 1387.1606 - accuracy: 0.9270\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 672.0223 - accuracy: 0.9382\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 733.6065 - accuracy: 0.9402\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 771.8187 - accuracy: 0.9407\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 654.2948 - accuracy: 0.9418\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 94.94%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "embedding 을 훈련시키기 위한 간단한 Neural Net Classifier\n",
    "'''\n",
    "\n",
    "def create_nn_model(encoder):\n",
    "    inputs = create_model_inputs()\n",
    "    embeddings = encoder(inputs)\n",
    "    output = layers.Dense(units=1, activation=\"sigmoid\")(embeddings)\n",
    "\n",
    "    nn_model = keras.Model(inputs=inputs, outputs=output)\n",
    "    nn_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(\"accuracy\")],\n",
    "    )\n",
    "    return nn_model\n",
    "\n",
    "\n",
    "embedding_encoder = create_embedding_encoder(size=64, hidden_layers=1)\n",
    "run_experiment(\n",
    "    create_nn_model(embedding_encoder),\n",
    "    train_data,\n",
    "    test_data,\n",
    "    num_epochs=5,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfed78bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpp4uiw7ix as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:06.206115. Found 199523 examples.\n",
      "Training model...\n",
      "Model trained in 0:02:52.849531\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO kernel.cc:1176] Loading model from path /tmp/tmpp4uiw7ix/model/ with prefix 94e578a55c5a4584\n",
      "[INFO abstract_model.cc:1248] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO kernel.cc:1022] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 95.32%\n"
     ]
    }
   ],
   "source": [
    "gbt_model = create_gbt_with_preprocessor(embedding_encoder)\n",
    "run_experiment(gbt_model, train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8604f13",
   "metadata": {},
   "source": [
    "## Better Neural Net works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b772c0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/numpy/core/numeric.py:2446: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 18s 38ms/step - loss: 8578.7705 - accuracy: 0.9020\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 3967.7239 - accuracy: 0.9193\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 2297.4883 - accuracy: 0.9244\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1855.9182 - accuracy: 0.9251\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1454.2272 - accuracy: 0.9287\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 94.29%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "hidden layer 추가\n",
    "'''\n",
    "embedding_encoder = create_embedding_encoder(size=64, hidden_layers=2)\n",
    "run_experiment(\n",
    "    create_nn_model(embedding_encoder),\n",
    "    train_data,\n",
    "    test_data,\n",
    "    num_epochs=5,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35fa9777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpfm95cg00 as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n",
      "/home/dhlee/anaconda3/envs/p38/lib/python3.8/site-packages/tensorflow_decision_forests/keras/core_inference.py:876: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = features_dataframe.drop(weight, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument batch_size=None not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:05.927508. Found 199523 examples.\n",
      "Training model...\n",
      "Model trained in 0:02:30.253590\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO kernel.cc:1176] Loading model from path /tmp/tmpfm95cg00/model/ with prefix a9cbca79e8ce43c3\n",
      "[INFO abstract_model.cc:1248] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO kernel.cc:1022] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 95.28%\n"
     ]
    }
   ],
   "source": [
    "gbt_model = create_gbt_with_preprocessor(embedding_encoder)\n",
    "run_experiment(gbt_model, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905403f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
